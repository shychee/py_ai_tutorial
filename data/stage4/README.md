# Stage 4 æ•°æ®é›†ä¸é¢„è®­ç»ƒæ¨¡å‹

**é˜¶æ®µ**: Stage 4 - æ·±åº¦å­¦ä¹ 
**æ›´æ–°æ—¥æœŸ**: 2025-11-17

---

## ğŸ“¦ æ•°æ®é›†æ¦‚è§ˆ

Stage 4 åŒ…å«æ·±åº¦å­¦ä¹ è®­ç»ƒæ‰€éœ€çš„æ ‡å‡†æ•°æ®é›†å’Œé¢„è®­ç»ƒæ¨¡å‹æƒé‡ã€‚

### å¿…éœ€æ•°æ®é›† (Required)

| æ•°æ®é›† | å¤§å° | ç±»å‹ | ç”¨é€” | è‡ªåŠ¨ä¸‹è½½ |
|-------|------|------|------|---------|
| **MNIST** | ~11 MB | å›¾åƒåˆ†ç±» | æ‰‹å†™æ•°å­—è¯†åˆ«(0-9) | âœ… PyTorch |
| **CIFAR-10** | ~170 MB | å›¾åƒåˆ†ç±» | 10ç±»ç‰©ä½“è¯†åˆ« | âœ… PyTorch |
| **IMDB** | ~80 MB | æ–‡æœ¬åˆ†ç±» | ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†æ | âœ… HuggingFace |

### å¯é€‰æ•°æ®é›† (Optional)

| æ•°æ®é›† | å¤§å° | ç±»å‹ | ç”¨é€” | ä¸‹è½½æ–¹å¼ |
|-------|------|------|------|---------|
| **CIFAR-100** | ~170 MB | å›¾åƒåˆ†ç±» | 100ç±»ç‰©ä½“è¯†åˆ« | PyTorch |
| **ImageNet Sample** | ~1 GB | å›¾åƒåˆ†ç±» | è¿ç§»å­¦ä¹ è®­ç»ƒ | æ‰‹åŠ¨ä¸‹è½½ |
| **COCO Sample** | ~500 MB | ç›®æ ‡æ£€æµ‹ | YOLOv8è®­ç»ƒ | æ‰‹åŠ¨ä¸‹è½½ |

---

## ğŸ¤– é¢„è®­ç»ƒæ¨¡å‹

### å¿…éœ€æ¨¡å‹ (Required)

| æ¨¡å‹ | å¤§å° | æ¡†æ¶ | ç”¨é€” | è‡ªåŠ¨ä¸‹è½½ |
|------|------|------|------|---------|
| **ResNet-50** | ~100 MB | PyTorch | CNNè¿ç§»å­¦ä¹  | âœ… é¦–æ¬¡ä½¿ç”¨æ—¶ |

### å¯é€‰æ¨¡å‹ (Optional)

| æ¨¡å‹ | å¤§å° | æ¡†æ¶ | ç”¨é€” | ä¸‹è½½æ–¹å¼ |
|------|------|------|------|---------|
| **BERT-base-uncased** | ~440 MB | PyTorch/TF | NLPé¢„è®­ç»ƒ | HuggingFace |
| **YOLOv8n** | ~6 MB | PyTorch | ç›®æ ‡æ£€æµ‹ | Ultralytics |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼1: è‡ªåŠ¨ä¸‹è½½ï¼ˆæ¨èï¼‰

è¿è¡Œä¸‹è½½è„šæœ¬è‡ªåŠ¨è·å–æ‰€æœ‰å¿…éœ€æ•°æ®é›†ï¼š

```bash
# ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
python scripts/data/download-stage4.py

# ä»…ä¸‹è½½æ•°æ®é›†ï¼ˆè·³è¿‡æ¨¡å‹ï¼‰
python scripts/data/download-stage4.py --skip-models

# ä¸‹è½½æŒ‡å®šæ•°æ®é›†
python scripts/data/download-stage4.py --dataset DS-S4-MNIST

# ä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿï¼ˆå¼€å‘ä¸­ï¼‰
python scripts/data/download-stage4.py --mirror
```

### æ–¹å¼2: åœ¨ä»£ç ä¸­è‡ªåŠ¨ä¸‹è½½

å¤§å¤šæ•°æ•°æ®é›†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½ï¼š

```python
import torchvision

# MNIST è‡ªåŠ¨ä¸‹è½½
train_dataset = torchvision.datasets.MNIST(
    root='./data/stage4/mnist',
    train=True,
    download=True  # é¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½
)

# CIFAR-10 è‡ªåŠ¨ä¸‹è½½
cifar_dataset = torchvision.datasets.CIFAR10(
    root='./data/stage4/cifar10',
    train=True,
    download=True
)
```

### æ–¹å¼3: ç¦»çº¿æ•°æ®åŒ…

å¦‚æœç½‘ç»œå—é™ï¼Œå¯ä»¥ä½¿ç”¨é¢„æ‰“åŒ…çš„ç¦»çº¿æ•°æ®ï¼š

```bash
# ä¸‹è½½ç¦»çº¿åŒ…ï¼ˆå‡è®¾ä»æœåŠ¡å™¨è·å–ï¼‰
# offline/stage4-data.tar.gz (~2GB, åŒ…å«MNIST/CIFAR-10/IMDB)
# offline/stage4-models.tar.gz (~500MB, åŒ…å«ResNet-50æƒé‡)

# è§£å‹åˆ°æ•°æ®ç›®å½•
tar -xzf offline/stage4-data.tar.gz -C data/stage4/
tar -xzf offline/stage4-models.tar.gz -C data/models/
```

---

## ğŸ“ ç›®å½•ç»“æ„

ä¸‹è½½å®Œæˆåï¼Œç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

```
data/stage4/
â”œâ”€â”€ mnist/                          # MNIST æ•°æ®é›†
â”‚   â”œâ”€â”€ MNIST/
â”‚   â”‚   â””â”€â”€ raw/
â”‚   â”‚       â”œâ”€â”€ train-images-idx3-ubyte.gz
â”‚   â”‚       â”œâ”€â”€ train-labels-idx1-ubyte.gz
â”‚   â”‚       â”œâ”€â”€ t10k-images-idx3-ubyte.gz
â”‚   â”‚       â””â”€â”€ t10k-labels-idx1-ubyte.gz
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ training.pt
â”‚       â””â”€â”€ test.pt
â”‚
â”œâ”€â”€ cifar10/                        # CIFAR-10 æ•°æ®é›†
â”‚   â””â”€â”€ cifar-10-batches-py/
â”‚       â”œâ”€â”€ data_batch_1
â”‚       â”œâ”€â”€ data_batch_2
â”‚       â”œâ”€â”€ data_batch_3
â”‚       â”œâ”€â”€ data_batch_4
â”‚       â”œâ”€â”€ data_batch_5
â”‚       â”œâ”€â”€ test_batch
â”‚       â”œâ”€â”€ batches.meta
â”‚       â””â”€â”€ readme.html
â”‚
â”œâ”€â”€ cifar100/                       # CIFAR-100 (å¯é€‰)
â”‚   â””â”€â”€ cifar-100-python/
â”‚       â”œâ”€â”€ train
â”‚       â”œâ”€â”€ test
â”‚       â””â”€â”€ meta
â”‚
â”œâ”€â”€ imdb/                           # IMDB ç”µå½±è¯„è®º
â”‚   â””â”€â”€ imdb/
â”‚       â””â”€â”€ 1.0.0/
â”‚           â”œâ”€â”€ train/
â”‚           â”œâ”€â”€ test/
â”‚           â””â”€â”€ unsupervised/
â”‚
â”œâ”€â”€ imagenet-sample/                # ImageNet æ ·æœ¬ (å¯é€‰)
â”‚   â””â”€â”€ imagenette2/
â”‚       â”œâ”€â”€ train/
â”‚       â””â”€â”€ val/
â”‚
â””â”€â”€ coco-sample/                    # COCO æ ·æœ¬ (å¯é€‰)
    â””â”€â”€ val2017/
        â”œâ”€â”€ 000000000139.jpg
        â”œâ”€â”€ 000000000285.jpg
        â””â”€â”€ ...

data/models/                        # é¢„è®­ç»ƒæ¨¡å‹æƒé‡
â”œâ”€â”€ resnet50_pytorch.pth           # ResNet-50 PyTorchæƒé‡
â”œâ”€â”€ bert-base-uncased/             # BERTæ¨¡å‹ (å¯é€‰)
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â””â”€â”€ vocab.txt
â””â”€â”€ yolov8n.pt                     # YOLOv8 Nano (å¯é€‰)
```

---

## ğŸ“Š æ•°æ®é›†è¯¦ç»†è¯´æ˜

### 1. MNIST æ‰‹å†™æ•°å­—æ•°æ®é›†

**ç®€ä»‹**: 60,000å¼ è®­ç»ƒå›¾åƒ + 10,000å¼ æµ‹è¯•å›¾åƒï¼Œ28Ã—28ç°åº¦å›¾åƒ

**ç±»åˆ«**: æ•°å­— 0-9

**ä½¿ç”¨ç¤ºä¾‹**:
```python
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

train_dataset = torchvision.datasets.MNIST(
    root='./data/stage4/mnist',
    train=True,
    download=True,
    transform=transform
)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
```

**ç”¨äº**:
- `notebooks/stage4/02-pytorch-basics.ipynb`
- ç¥ç»ç½‘ç»œåŸºç¡€æ•™å­¦

---

### 2. CIFAR-10 å›¾åƒåˆ†ç±»æ•°æ®é›†

**ç®€ä»‹**: 60,000å¼ 32Ã—32å½©è‰²å›¾åƒï¼Œ10ä¸ªç±»åˆ«

**ç±»åˆ«**: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck

**ä½¿ç”¨ç¤ºä¾‹**:
```python
import torchvision

# æ•°æ®å¢å¼º
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
])

trainset = torchvision.datasets.CIFAR10(
    root='./data/stage4/cifar10',
    train=True,
    download=True,
    transform=transform_train
)
```

**ç”¨äº**:
- `notebooks/stage4/03-cnn-image-classification.ipynb`
- CNNåŸºç¡€ä¸è¿ç§»å­¦ä¹ 

---

### 3. IMDB ç”µå½±è¯„è®ºæ•°æ®é›†

**ç®€ä»‹**: 50,000æ¡ç”µå½±è¯„è®ºï¼ŒäºŒåˆ†ç±»æƒ…æ„Ÿåˆ†æ

**ç±»åˆ«**: Positive (æ­£é¢) / Negative (è´Ÿé¢)

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from datasets import load_dataset

# åŠ è½½æ•°æ®é›†
dataset = load_dataset('imdb', cache_dir='./data/stage4/imdb')

# æŸ¥çœ‹æ ·æœ¬
print(dataset['train'][0])
# {'text': '...', 'label': 1}  # 1=positive, 0=negative
```

**ç”¨äº**:
- `notebooks/stage4/04-rnn-text-classification.ipynb`
- RNN/LSTM/BERTæ–‡æœ¬åˆ†ç±»

---

### 4. CIFAR-100 å›¾åƒåˆ†ç±»æ•°æ®é›† (å¯é€‰)

**ç®€ä»‹**: 60,000å¼ 32Ã—32å½©è‰²å›¾åƒï¼Œ100ä¸ªç»†ç²’åº¦ç±»åˆ«

**ç±»åˆ«**: 100ä¸ªç±»åˆ«ï¼Œåˆ†ä¸º20ä¸ªè¶…ç±»

**ä½¿ç”¨ç¤ºä¾‹**:
```python
trainset = torchvision.datasets.CIFAR100(
    root='./data/stage4/cifar100',
    train=True,
    download=True,
    transform=transform
)
```

**ç”¨äº**:
- CNNè¿›é˜¶å®éªŒ
- ç»†ç²’åº¦åˆ†ç±»ä»»åŠ¡

---

### 5. ImageNet Sample (å¯é€‰)

**ç®€ä»‹**: ImageNet-1Kçš„ç²¾ç®€ç‰ˆæœ¬ï¼ŒåŒ…å«10ä¸ªç±»åˆ«

**å¤§å°**: ~1GB

**ä¸‹è½½æ–¹å¼**:
```bash
# ä½¿ç”¨è„šæœ¬ä¸‹è½½
python scripts/data/download-stage4.py --dataset DS-S4-IMAGENET-SAMPLE

# æˆ–æ‰‹åŠ¨ä¸‹è½½
wget https://github.com/fastai/imagenette/releases/download/v0.3/imagenette2.tgz
tar -xzf imagenette2.tgz -C data/stage4/imagenet-sample/
```

**ç”¨äº**:
- è¿ç§»å­¦ä¹ å®æˆ˜
- `docs/stage4/projects/p01-industrial-vision/`

---

### 6. COCO Sample (å¯é€‰)

**ç®€ä»‹**: COCO 2017éªŒè¯é›†æ ·æœ¬

**å¤§å°**: ~500MB (1000å¼ å›¾åƒ)

**ä¸‹è½½æ–¹å¼**:
```bash
# æ‰‹åŠ¨ä¸‹è½½
wget http://images.cocodataset.org/zips/val2017.zip
unzip val2017.zip -d data/stage4/coco-sample/
```

**ç”¨äº**:
- ç›®æ ‡æ£€æµ‹ä»»åŠ¡
- `docs/stage4/projects/p02-yolov11-realtime/`

---

## ğŸ” é¢„è®­ç»ƒæ¨¡å‹è¯¦ç»†è¯´æ˜

### 1. ResNet-50 (PyTorch)

**ç®€ä»‹**: åœ¨ImageNet-1Kä¸Šé¢„è®­ç»ƒçš„ResNet-50æ¨¡å‹

**å‚æ•°é‡**: ~25M

**ä½¿ç”¨ç¤ºä¾‹**:
```python
import torchvision.models as models

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model = models.resnet50(pretrained=True)

# å†»ç»“å·ç§¯å±‚ï¼Œä»…è®­ç»ƒæœ€åçš„å…¨è¿æ¥å±‚
for param in model.parameters():
    param.requires_grad = False

# æ›¿æ¢æœ€åä¸€å±‚ç”¨äºè‡ªå·±çš„ä»»åŠ¡
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 10)  # 10ç±»åˆ†ç±»
```

**ç”¨äº**:
- `notebooks/stage4/03-cnn-image-classification.ipynb`
- è¿ç§»å­¦ä¹ æ•™ç¨‹

---

### 2. BERT-base-uncased (å¯é€‰)

**ç®€ä»‹**: 12å±‚Transformerç¼–ç å™¨ï¼Œ110Må‚æ•°

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from transformers import BertTokenizer, BertForSequenceClassification

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', cache_dir='./data/models/bert-base-uncased')
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2, cache_dir='./data/models/bert-base-uncased')

# ä½¿ç”¨
inputs = tokenizer("Hello, world!", return_tensors="pt")
outputs = model(**inputs)
```

**ç”¨äº**:
- `notebooks/stage4/04-rnn-text-classification.ipynb`
- NLPé¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ

---

### 3. YOLOv8n (å¯é€‰)

**ç®€ä»‹**: YOLOv8 Nanoç‰ˆæœ¬ï¼Œè½»é‡çº§ç›®æ ‡æ£€æµ‹æ¨¡å‹

**å‚æ•°é‡**: ~3M

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from ultralytics import YOLO

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model = YOLO('yolov8n.pt')

# è®­ç»ƒ
model.train(data='coco.yaml', epochs=100)

# æ¨ç†
results = model('path/to/image.jpg')
```

**ç”¨äº**:
- `docs/stage4/projects/p02-yolov11-realtime/`
- å®æ—¶ç›®æ ‡æ£€æµ‹

---

## âš™ï¸ ç¯å¢ƒè¦æ±‚

### Python ä¾èµ–

```bash
# å¿…éœ€
pip install torch torchvision

# å¯é€‰ï¼ˆæ ¹æ®éœ€è¦å®‰è£…ï¼‰
pip install transformers datasets
pip install ultralytics  # YOLOv8
```

### ç¡¬ä»¶è¦æ±‚

| æ•°æ®é›†/æ¨¡å‹ | CPU | GPU | å†…å­˜ | ç¡¬ç›˜ |
|------------|-----|-----|------|------|
| MNIST/CIFAR-10 | âœ… | å¯é€‰ | 4GB | 200MB |
| IMDB | âœ… | å¯é€‰ | 8GB | 100MB |
| ResNet-50 è¿ç§»å­¦ä¹  | âœ… | æ¨è | 8GB | 100MB |
| BERT å¾®è°ƒ | âŒ | **å¿…éœ€** | 16GB | 500MB |
| YOLOv8 è®­ç»ƒ | âŒ | **å¿…éœ€** | 16GB | 1GB |

**GPU æ¨è**:
- å…¥é—¨: NVIDIA GTX 1060 (6GB VRAM)
- æ¨è: NVIDIA RTX 3060 (12GB VRAM)
- ä¸“ä¸š: NVIDIA A100 (40GB VRAM)

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### Q1: ä¸‹è½½é€Ÿåº¦æ…¢æˆ–å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
1. ä½¿ç”¨å›½å†…é•œåƒï¼ˆå¼€å‘ä¸­ï¼‰
2. ä½¿ç”¨ä»£ç†: `export https_proxy=http://127.0.0.1:7890`
3. ä¸‹è½½ç¦»çº¿åŒ…: å‚è§"æ–¹å¼3: ç¦»çº¿æ•°æ®åŒ…"

### Q2: PyTorch æ•°æ®é›†æŸå

**è§£å†³æ–¹æ¡ˆ**:
```bash
# åˆ é™¤ç¼“å­˜å¹¶é‡æ–°ä¸‹è½½
rm -rf data/stage4/mnist/
python -c "import torchvision; torchvision.datasets.MNIST(root='./data/stage4/mnist', download=True)"
```

### Q3: HuggingFace ä¸‹è½½å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
```bash
# è®¾ç½®é•œåƒï¼ˆå›½å†…ï¼‰
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–ä½¿ç”¨ç¦»çº¿æ¨¡å¼
export TRANSFORMERS_OFFLINE=1
```

### Q4: GPU å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
1. å‡å° batch_size
2. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ: `torch.cuda.amp`
3. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
4. ä½¿ç”¨ CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰

---

## ğŸ“š å‚è€ƒèµ„æ–™

### æ•°æ®é›†æ¥æº

- **MNIST**: [Yann LeCun's Website](http://yann.lecun.com/exdb/mnist/)
- **CIFAR-10/100**: [University of Toronto](https://www.cs.toronto.edu/~kriz/cifar.html)
- **IMDB**: [Stanford AI Lab](https://ai.stanford.edu/~amaas/data/sentiment/)
- **ImageNet**: [ImageNet Official](https://image-net.org/)
- **COCO**: [COCO Dataset](https://cocodataset.org/)

### é¢„è®­ç»ƒæ¨¡å‹æ¥æº

- **ResNet**: [PyTorch Hub](https://pytorch.org/hub/pytorch_vision_resnet/)
- **BERT**: [HuggingFace Hub](https://huggingface.co/bert-base-uncased)
- **YOLOv8**: [Ultralytics](https://github.com/ultralytics/ultralytics)

---

## ğŸ“ æ›´æ–°æ—¥å¿—

### 2025-11-17
- âœ… åˆ›å»º Stage 4 æ•°æ®é›†ä¸‹è½½è„šæœ¬
- âœ… æ”¯æŒ MNISTã€CIFAR-10ã€IMDB è‡ªåŠ¨ä¸‹è½½
- âœ… æ”¯æŒ ResNet-50ã€BERTã€YOLOv8 æ¨¡å‹ä¸‹è½½
- âœ… æ·»åŠ ç¦»çº¿æ•°æ®åŒ…æ”¯æŒï¼ˆè®¡åˆ’ä¸­ï¼‰

---

## ğŸ†˜ è·å–å¸®åŠ©

é‡åˆ°é—®é¢˜ï¼Ÿ

1. æŸ¥çœ‹ [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥) éƒ¨åˆ†
2. è¿è¡ŒéªŒè¯è„šæœ¬: `python scripts/data/verify.py --stage 4`
3. æŸ¥çœ‹ [è·¨å¹³å°æ•…éšœæ¢å¤æ¸…å•](../../docs/cross-platform/troubleshooting.md)
4. æäº¤ Issue: [GitHub Issues](https://github.com/yourusername/py_ai_tutorial/issues)

---

**ä¸Šä¸€é˜¶æ®µ**: [Stage 3 æ•°æ®é›†](../stage3/README.md)
**è¿”å›**: [é¡¹ç›®æ ¹ç›®å½•](../../README.md)
