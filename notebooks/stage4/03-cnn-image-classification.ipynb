{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNå›¾åƒåˆ†ç±»ï¼šä»é›¶å®ç°åˆ°è¿ç§»å­¦ä¹ \n",
    "\n",
    "**ç›®æ ‡**: ç†è§£CNNæ¶æ„ï¼ŒæŒæ¡è¿ç§»å­¦ä¹ æŠ€æœ¯\n",
    "\n",
    "**é¢„è®¡æ—¶é—´**: 90-120åˆ†é’Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ æœ¬Notebookå†…å®¹\n",
    "\n",
    "1. æ•°æ®å‡†å¤‡ï¼šCIFAR-10æ•°æ®é›†\n",
    "2. ä»é›¶å®ç°ç®€å•CNN\n",
    "3. å¯è§†åŒ–å·ç§¯æ ¸å’Œç‰¹å¾å›¾\n",
    "4. ä½¿ç”¨é¢„è®­ç»ƒResNet-50è¿›è¡Œè¿ç§»å­¦ä¹ \n",
    "5. å¯¹æ¯”ä»é›¶è®­ç»ƒvsè¿ç§»å­¦ä¹ \n",
    "6. æ¨¡å‹è¯„ä¼°ä¸å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# æ£€æµ‹è®¾å¤‡\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'ä½¿ç”¨è®¾å¤‡: {device}')\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬1éƒ¨åˆ†: æ•°æ®å‡†å¤‡\n",
    "\n",
    "CIFAR-10åŒ…å«10ä¸ªç±»åˆ«çš„60000å¼ 32Ã—32å½©è‰²å›¾åƒï¼Œæ¯ç±»6000å¼ ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®å¢å¼º\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# ä¸‹è½½å¹¶åŠ è½½æ•°æ®é›†\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test\n",
    ")\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "# CIFAR-10ç±»åˆ«\n",
    "classes = ('é£æœº', 'æ±½è½¦', 'é¸Ÿ', 'çŒ«', 'é¹¿', 'ç‹—', 'é’è›™', 'é©¬', 'èˆ¹', 'å¡è½¦')\n",
    "\n",
    "print(f'è®­ç»ƒé›†å¤§å°: {len(trainset)}')\n",
    "print(f'æµ‹è¯•é›†å¤§å°: {len(testset)}')\n",
    "print(f'ç±»åˆ«æ•°: {len(classes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–éƒ¨åˆ†æ•°æ®\n",
    "def show_images(images, labels, preds=None, n=16):\n",
    "    \"\"\"æ˜¾ç¤ºå›¾åƒç½‘æ ¼\"\"\"\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(n, len(images))):\n",
    "        # åå½’ä¸€åŒ–\n",
    "        img = images[i].cpu().numpy().transpose((1, 2, 0))\n",
    "        mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "        std = np.array([0.2023, 0.1994, 0.2010])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        title = f'çœŸå®: {classes[labels[i]]}'\n",
    "        if preds is not None:\n",
    "            title += f'\\né¢„æµ‹: {classes[preds[i]]}'\n",
    "            color = 'green' if labels[i] == preds[i] else 'red'\n",
    "            axes[i].set_title(title, color=color)\n",
    "        else:\n",
    "            axes[i].set_title(title)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# æ˜¾ç¤ºä¸€æ‰¹è®­ç»ƒæ•°æ®\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "show_images(images, labels, n=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬2éƒ¨åˆ†: ä»é›¶å®ç°CNN\n",
    "\n",
    "æ„å»ºä¸€ä¸ªç®€å•çš„CNNæ¶æ„ï¼š3ä¸ªå·ç§¯å±‚ + 2ä¸ªå…¨è¿æ¥å±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"ç®€å•çš„CNNæ¶æ„\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # å·ç§¯å±‚\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # å…¨è¿æ¥å±‚\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # å·ç§¯å—1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # å·ç§¯å—2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # å·ç§¯å—3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # å…¨è¿æ¥å±‚\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "model_simple = SimpleCNN(num_classes=10).to(device)\n",
    "\n",
    "# æ‰“å°æ¨¡å‹ç»“æ„\n",
    "print(model_simple)\n",
    "\n",
    "# è®¡ç®—å‚æ•°é‡\n",
    "total_params = sum(p.numel() for p in model_simple.parameters())\n",
    "trainable_params = sum(p.numel() for p in model_simple.parameters() if p.requires_grad)\n",
    "print(f'\\næ€»å‚æ•°é‡: {total_params:,}')\n",
    "print(f'å¯è®­ç»ƒå‚æ•°: {trainable_params:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è®­ç»ƒå‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, testloader, epochs=10, lr=0.001):\n",
    "    \"\"\"è®­ç»ƒæ¨¡å‹\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # è®­ç»ƒé˜¶æ®µ\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(trainloader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': running_loss / (pbar.n + 1),\n",
    "                'acc': 100. * correct / total\n",
    "            })\n",
    "        \n",
    "        train_loss = running_loss / len(trainloader)\n",
    "        train_acc = 100. * correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        \n",
    "        # æµ‹è¯•é˜¶æ®µ\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        test_acc = 100. * correct / total\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%')\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    return train_losses, train_accs, test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒç®€å•CNNï¼ˆå»ºè®®ä½¿ç”¨GPUï¼ŒCPUä¼šå¾ˆæ…¢ï¼‰\n",
    "print(\"å¼€å§‹è®­ç»ƒç®€å•CNN...\")\n",
    "train_losses, train_accs, test_accs = train_model(\n",
    "    model_simple,\n",
    "    trainloader,\n",
    "    testloader,\n",
    "    epochs=10,\n",
    "    lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(train_losses, label='è®­ç»ƒæŸå¤±')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('æŸå¤±')\n",
    "ax1.set_title('è®­ç»ƒæŸå¤±æ›²çº¿')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(train_accs, label='è®­ç»ƒå‡†ç¡®ç‡')\n",
    "ax2.plot(test_accs, label='æµ‹è¯•å‡†ç¡®ç‡')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('å‡†ç¡®ç‡ (%)')\n",
    "ax2.set_title('å‡†ç¡®ç‡æ›²çº¿')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\næœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {test_accs[-1]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬3éƒ¨åˆ†: å¯è§†åŒ–å·ç§¯æ ¸\n",
    "\n",
    "æŸ¥çœ‹ç¬¬ä¸€å±‚å·ç§¯æ ¸å­¦åˆ°çš„æ»¤æ³¢å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_filters(model, layer_name='conv1', n_filters=32):\n",
    "    \"\"\"å¯è§†åŒ–å·ç§¯æ ¸\"\"\"\n",
    "    # è·å–ç¬¬ä¸€å±‚å·ç§¯æ ¸æƒé‡\n",
    "    conv1_weights = model.conv1.weight.data.cpu()\n",
    "    \n",
    "    # å½’ä¸€åŒ–åˆ°[0, 1]\n",
    "    conv1_weights = (conv1_weights - conv1_weights.min()) / (conv1_weights.max() - conv1_weights.min())\n",
    "    \n",
    "    # ç»˜åˆ¶å·ç§¯æ ¸\n",
    "    fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(n_filters, conv1_weights.shape[0])):\n",
    "        # è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼ (H, W, C)\n",
    "        kernel = conv1_weights[i].permute(1, 2, 0).numpy()\n",
    "        axes[i].imshow(kernel)\n",
    "        axes[i].set_title(f'æ»¤æ³¢å™¨ {i+1}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('ç¬¬ä¸€å±‚å·ç§¯æ ¸å¯è§†åŒ–', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_filters(model_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¯è§†åŒ–ç‰¹å¾å›¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(model, image, layer_names=['conv1', 'conv2', 'conv3']):\n",
    "    \"\"\"å¯è§†åŒ–ç‰¹å¾å›¾\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # æ³¨å†Œé’©å­å‡½æ•°è·å–ä¸­é—´å±‚è¾“å‡º\n",
    "    activations = {}\n",
    "    \n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activations[name] = output.detach()\n",
    "        return hook\n",
    "    \n",
    "    # æ³¨å†Œé’©å­\n",
    "    hooks = []\n",
    "    for name in layer_names:\n",
    "        layer = getattr(model, name)\n",
    "        hooks.append(layer.register_forward_hook(get_activation(name)))\n",
    "    \n",
    "    # å‰å‘ä¼ æ’­\n",
    "    with torch.no_grad():\n",
    "        _ = model(image.unsqueeze(0).to(device))\n",
    "    \n",
    "    # ç§»é™¤é’©å­\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "    \n",
    "    # å¯è§†åŒ–\n",
    "    fig, axes = plt.subplots(len(layer_names), 8, figsize=(16, len(layer_names)*2))\n",
    "    \n",
    "    for i, name in enumerate(layer_names):\n",
    "        feature_map = activations[name][0].cpu()\n",
    "        \n",
    "        for j in range(8):\n",
    "            if j < feature_map.shape[0]:\n",
    "                axes[i, j].imshow(feature_map[j], cmap='viridis')\n",
    "                axes[i, j].set_title(f'{name} - ch{j+1}')\n",
    "            axes[i, j].axis('off')\n",
    "    \n",
    "    plt.suptitle('ä¸åŒå±‚çš„ç‰¹å¾å›¾å¯è§†åŒ–', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# é€‰æ‹©ä¸€å¼ å›¾åƒ\n",
    "test_image, test_label = testset[0]\n",
    "print(f'å›¾åƒç±»åˆ«: {classes[test_label]}')\n",
    "\n",
    "# æ˜¾ç¤ºåŸå›¾\n",
    "img = test_image.numpy().transpose((1, 2, 0))\n",
    "mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "std = np.array([0.2023, 0.1994, 0.2010])\n",
    "img = std * img + mean\n",
    "img = np.clip(img, 0, 1)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(img)\n",
    "plt.title(f'åŸå›¾: {classes[test_label]}')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# å¯è§†åŒ–ç‰¹å¾å›¾\n",
    "visualize_feature_maps(model_simple, test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬4éƒ¨åˆ†: è¿ç§»å­¦ä¹  - ResNet-50\n",
    "\n",
    "ä½¿ç”¨é¢„è®­ç»ƒçš„ResNet-50è¿›è¡Œè¿ç§»å­¦ä¹ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½é¢„è®­ç»ƒResNet-50\n",
    "model_resnet = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "# å†»ç»“æ‰€æœ‰å·ç§¯å±‚\n",
    "for param in model_resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# æ›¿æ¢æœ€åçš„å…¨è¿æ¥å±‚\n",
    "num_ftrs = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "model_resnet = model_resnet.to(device)\n",
    "\n",
    "# æ‰“å°å¯è®­ç»ƒå‚æ•°\n",
    "trainable_params = sum(p.numel() for p in model_resnet.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model_resnet.parameters())\n",
    "print(f'æ€»å‚æ•°é‡: {total_params:,}')\n",
    "print(f'å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({100*trainable_params/total_params:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒResNet-50ï¼ˆåªè®­ç»ƒæœ€åä¸€å±‚ï¼Œä¼šå¾ˆå¿«ï¼‰\n",
    "print(\"å¼€å§‹è®­ç»ƒResNet-50ï¼ˆè¿ç§»å­¦ä¹ ï¼‰...\")\n",
    "train_losses_resnet, train_accs_resnet, test_accs_resnet = train_model(\n",
    "    model_resnet,\n",
    "    trainloader,\n",
    "    testloader,\n",
    "    epochs=5,\n",
    "    lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬5éƒ¨åˆ†: æ€§èƒ½å¯¹æ¯”\n",
    "\n",
    "å¯¹æ¯”ç®€å•CNN vs ResNet-50è¿ç§»å­¦ä¹ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹æ¯”å‡†ç¡®ç‡\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "epochs_simple = list(range(1, len(test_accs) + 1))\n",
    "epochs_resnet = list(range(1, len(test_accs_resnet) + 1))\n",
    "\n",
    "ax.plot(epochs_simple, test_accs, 'o-', label='ç®€å•CNNï¼ˆä»é›¶è®­ç»ƒï¼‰', linewidth=2)\n",
    "ax.plot(epochs_resnet, test_accs_resnet, 's-', label='ResNet-50ï¼ˆè¿ç§»å­¦ä¹ ï¼‰', linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('æµ‹è¯•å‡†ç¡®ç‡ (%)', fontsize=12)\n",
    "ax.set_title('æ¨¡å‹æ€§èƒ½å¯¹æ¯”', fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== æ€§èƒ½å¯¹æ¯”æ€»ç»“ ===\")\n",
    "print(f\"ç®€å•CNNæœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {test_accs[-1]:.2f}%\")\n",
    "print(f\"ResNet-50è¿ç§»å­¦ä¹ æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {test_accs_resnet[-1]:.2f}%\")\n",
    "print(f\"å‡†ç¡®ç‡æå‡: {test_accs_resnet[-1] - test_accs[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬6éƒ¨åˆ†: æ¨¡å‹è¯„ä¼°\n",
    "\n",
    "è¯¦ç»†è¯„ä¼°æ¨¡å‹æ€§èƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools\n",
    "\n",
    "def evaluate_model(model, testloader):\n",
    "    \"\"\"è¯„ä¼°æ¨¡å‹å¹¶ç”Ÿæˆæ··æ·†çŸ©é˜µ\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    return np.array(all_labels), np.array(all_preds)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='æ··æ·†çŸ©é˜µ'):\n",
    "    \"\"\"ç»˜åˆ¶æ··æ·†çŸ©é˜µ\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.ylabel('çœŸå®ç±»åˆ«', fontsize=12)\n",
    "    plt.xlabel('é¢„æµ‹ç±»åˆ«', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# è¯„ä¼°ResNet-50\n",
    "labels, preds = evaluate_model(model_resnet, testloader)\n",
    "cm = confusion_matrix(labels, preds)\n",
    "plot_confusion_matrix(cm, classes, title='ResNet-50è¿ç§»å­¦ä¹  - æ··æ·†çŸ©é˜µ')\n",
    "\n",
    "# æ‰“å°åˆ†ç±»æŠ¥å‘Š\n",
    "print(\"\\n=== åˆ†ç±»æŠ¥å‘Š ===\")\n",
    "print(classification_report(labels, preds, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–é¢„æµ‹ç»“æœ\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "model_resnet.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model_resnet(images.to(device))\n",
    "    _, preds = outputs.max(1)\n",
    "\n",
    "show_images(images, labels, preds.cpu(), n=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ æ€»ç»“\n",
    "\n",
    "é€šè¿‡æœ¬Notebookï¼Œæˆ‘ä»¬ï¼š\n",
    "\n",
    "1. âœ… ä»é›¶å®ç°äº†ç®€å•CNNï¼Œç†è§£äº†å·ç§¯ã€æ± åŒ–ã€BNå±‚çš„ä½œç”¨\n",
    "2. âœ… å¯è§†åŒ–äº†å·ç§¯æ ¸å’Œç‰¹å¾å›¾ï¼Œç›´è§‚ç†è§£CNNå­¦åˆ°çš„ç‰¹å¾\n",
    "3. âœ… ä½¿ç”¨é¢„è®­ç»ƒResNet-50è¿›è¡Œè¿ç§»å­¦ä¹ \n",
    "4. âœ… å¯¹æ¯”äº†ä»é›¶è®­ç»ƒvsè¿ç§»å­¦ä¹ çš„æ€§èƒ½å·®å¼‚\n",
    "5. âœ… è¯¦ç»†è¯„ä¼°äº†æ¨¡å‹æ€§èƒ½ï¼ˆæ··æ·†çŸ©é˜µã€åˆ†ç±»æŠ¥å‘Šï¼‰\n",
    "\n",
    "### å…³é”®è¦ç‚¹\n",
    "\n",
    "- **CNNæ¶æ„**: å·ç§¯å±‚æå–ç‰¹å¾ï¼Œæ± åŒ–å±‚é™ç»´ï¼Œå…¨è¿æ¥å±‚åˆ†ç±»\n",
    "- **è¿ç§»å­¦ä¹ **: åœ¨å°æ•°æ®é›†ä¸Šï¼Œè¿ç§»å­¦ä¹ æ˜¾è‘—ä¼˜äºä»é›¶è®­ç»ƒ\n",
    "- **ç‰¹å¾å±‚æ¬¡**: æµ…å±‚å­¦ä¹ è¾¹ç¼˜/çº¹ç†ï¼Œæ·±å±‚å­¦ä¹ é«˜çº§è¯­ä¹‰\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "- ğŸ¯ å°è¯•å¾®è°ƒResNetçš„åå‡ å±‚ï¼Œè§‚å¯Ÿæ€§èƒ½æå‡\n",
    "- ğŸ“š å­¦ä¹ å…¶ä»–ç»å…¸æ¶æ„ï¼ˆVGGã€EfficientNetï¼‰\n",
    "- ğŸš€ è¿›å…¥å®æˆ˜é¡¹ç›®ï¼š[P01: å·¥ä¸šè§†è§‰æ£€æµ‹](../../docs/stage4/projects/p01-industrial-vision/README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
