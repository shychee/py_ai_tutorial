{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# PyTorch åŸºç¡€ï¼šå¼ é‡æ“ä½œä¸è‡ªåŠ¨å¾®åˆ†\n",
    "\n",
    "**ç›®æ ‡**: æŒæ¡ PyTorch çš„æ ¸å¿ƒæ¦‚å¿µå’ŒåŸºç¡€æ“ä½œ\n",
    "\n",
    "**é¢„è®¡æ—¶é—´**: 60-90 åˆ†é’Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ æœ¬ Notebook å†…å®¹\n",
    "\n",
    "1. **å¼ é‡åŸºç¡€**: åˆ›å»ºã€æ“ä½œã€ç´¢å¼•ã€å½¢çŠ¶å˜æ¢\n",
    "2. **è‡ªåŠ¨å¾®åˆ†**: autograd æœºåˆ¶ä¸æ¢¯åº¦è®¡ç®—\n",
    "3. **ç¥ç»ç½‘ç»œæ¨¡å—**: nn.Moduleã€å±‚ã€æŸå¤±å‡½æ•°\n",
    "4. **ä¼˜åŒ–å™¨**: SGDã€Adamã€å­¦ä¹ ç‡è°ƒåº¦\n",
    "5. **å®Œæ•´è®­ç»ƒæµç¨‹**: æ•°æ®åŠ è½½ â†’ æ¨¡å‹å®šä¹‰ â†’ è®­ç»ƒ â†’ è¯„ä¼°\n",
    "6. **å®æˆ˜æ¡ˆä¾‹**: MNIST æ‰‹å†™æ•°å­—è¯†åˆ«"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¯å¢ƒè®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¯å¤ç°æ€§\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# æ£€æµ‹è®¾å¤‡ï¼ˆGPU/CPUï¼‰\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'PyTorch ç‰ˆæœ¬: {torch.__version__}')\n",
    "print(f'ä½¿ç”¨è®¾å¤‡: {device}')\n",
    "if device.type == 'cuda':\n",
    "    print(f'GPU åç§°: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'GPU æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬1éƒ¨åˆ†: å¼ é‡ï¼ˆTensorï¼‰åŸºç¡€\n",
    "\n",
    "å¼ é‡æ˜¯ PyTorch ä¸­çš„åŸºæœ¬æ•°æ®ç»“æ„ï¼Œç±»ä¼¼äº NumPy çš„æ•°ç»„ï¼Œä½†å¯ä»¥åœ¨ GPU ä¸Šè¿è¡Œä»¥åŠ é€Ÿè®¡ç®—ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tensor-creation",
   "metadata": {},
   "source": [
    "### 1.1 åˆ›å»ºå¼ é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-tensors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä» Python åˆ—è¡¨åˆ›å»º\n",
    "t1 = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(f'ä»åˆ—è¡¨åˆ›å»º: {t1}')\n",
    "print(f'æ•°æ®ç±»å‹: {t1.dtype}, å½¢çŠ¶: {t1.shape}')\n",
    "\n",
    "# åˆ›å»ºäºŒç»´å¼ é‡ï¼ˆçŸ©é˜µï¼‰\n",
    "t2 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(f'\\näºŒç»´å¼ é‡:\\n{t2}')\n",
    "print(f'å½¢çŠ¶: {t2.shape}, ç»´åº¦: {t2.ndim}')\n",
    "\n",
    "# ä» NumPy æ•°ç»„åˆ›å»º\n",
    "arr = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "t3 = torch.from_numpy(arr)\n",
    "print(f'\\nä» NumPy åˆ›å»º:\\n{t3}')\n",
    "\n",
    "# ç‰¹æ®Šå¼ é‡\n",
    "zeros = torch.zeros(2, 3)  # å…¨0å¼ é‡\n",
    "ones = torch.ones(2, 3)    # å…¨1å¼ é‡\n",
    "rand = torch.rand(2, 3)    # å‡åŒ€åˆ†å¸ƒéšæœºæ•° [0, 1)\n",
    "randn = torch.randn(2, 3)  # æ ‡å‡†æ­£æ€åˆ†å¸ƒéšæœºæ•°\n",
    "arange = torch.arange(0, 10, 2)  # ç­‰å·®æ•°åˆ—\n",
    "linspace = torch.linspace(0, 1, 5)  # çº¿æ€§é—´éš”\n",
    "\n",
    "print(f'\\nå…¨0å¼ é‡:\\n{zeros}')\n",
    "print(f'\\nå‡åŒ€åˆ†å¸ƒéšæœºæ•°:\\n{rand}')\n",
    "print(f'\\nç­‰å·®æ•°åˆ—: {arange}')\n",
    "print(f'çº¿æ€§é—´éš”: {linspace}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tensor-ops",
   "metadata": {},
   "source": [
    "### 1.2 å¼ é‡æ“ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tensor-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç®—æœ¯è¿ç®—\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "print(f'a + b = {a + b}')\n",
    "print(f'a * b = {a * b}')  # é€å…ƒç´ ä¹˜æ³•\n",
    "print(f'a ** 2 = {a ** 2}')\n",
    "\n",
    "# çŸ©é˜µè¿ç®—\n",
    "A = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "B = torch.tensor([[5.0, 6.0], [7.0, 8.0]])\n",
    "\n",
    "print(f'\\nçŸ©é˜µä¹˜æ³• A @ B:\\n{A @ B}')\n",
    "print(f'\\nè½¬ç½® A.T:\\n{A.T}')\n",
    "\n",
    "# èšåˆæ“ä½œ\n",
    "x = torch.randn(3, 4)\n",
    "print(f'\\nå¼ é‡ x:\\n{x}')\n",
    "print(f'æ±‚å’Œ: {x.sum()}')\n",
    "print(f'å‡å€¼: {x.mean()}')\n",
    "print(f'æœ€å¤§å€¼: {x.max()}')\n",
    "print(f'æ²¿è½´0æ±‚å’Œ: {x.sum(dim=0)}')\n",
    "print(f'æ²¿è½´1æ±‚å‡å€¼: {x.mean(dim=1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tensor-indexing",
   "metadata": {},
   "source": [
    "### 1.3 ç´¢å¼•ä¸åˆ‡ç‰‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indexing-slicing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºç¤ºä¾‹å¼ é‡\n",
    "t = torch.arange(24).reshape(2, 3, 4)\n",
    "print(f'åŸå§‹å¼ é‡ (2Ã—3Ã—4):\\n{t}')\n",
    "\n",
    "# ç´¢å¼•\n",
    "print(f'\\nt[0]: \\n{t[0]}')\n",
    "print(f'\\nt[0, 1]: {t[0, 1]}')\n",
    "print(f't[0, 1, 2]: {t[0, 1, 2]}')\n",
    "\n",
    "# åˆ‡ç‰‡\n",
    "print(f'\\nt[:, 0, :]: \\n{t[:, 0, :]}')\n",
    "print(f'\\nt[0, :, 1:3]: \\n{t[0, :, 1:3]}')\n",
    "\n",
    "# å¸ƒå°”ç´¢å¼•\n",
    "x = torch.randn(5)\n",
    "print(f'\\nx: {x}')\n",
    "print(f'x > 0: {x > 0}')\n",
    "print(f'x[x > 0]: {x[x > 0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tensor-reshape",
   "metadata": {},
   "source": [
    "### 1.4 å½¢çŠ¶å˜æ¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reshape-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºå¼ é‡\n",
    "x = torch.arange(12)\n",
    "print(f'åŸå§‹å¼ é‡: {x}, å½¢çŠ¶: {x.shape}')\n",
    "\n",
    "# reshape: æ”¹å˜å½¢çŠ¶ï¼ˆå¯èƒ½æ‹·è´æ•°æ®ï¼‰\n",
    "x_reshaped = x.reshape(3, 4)\n",
    "print(f'\\nreshape(3, 4):\\n{x_reshaped}')\n",
    "\n",
    "# view: æ”¹å˜å½¢çŠ¶ï¼ˆå…±äº«å†…å­˜ï¼‰\n",
    "x_view = x.view(2, 6)\n",
    "print(f'\\nview(2, 6):\\n{x_view}')\n",
    "\n",
    "# unsqueeze: å¢åŠ ç»´åº¦\n",
    "x_unsqueeze = x.unsqueeze(0)\n",
    "print(f'\\nunsqueeze(0): å½¢çŠ¶ {x_unsqueeze.shape}')\n",
    "\n",
    "# squeeze: ç§»é™¤å¤§å°ä¸º1çš„ç»´åº¦\n",
    "y = torch.randn(1, 3, 1, 4)\n",
    "print(f'\\nåŸå§‹å½¢çŠ¶: {y.shape}')\n",
    "print(f'squeeze() å: {y.squeeze().shape}')\n",
    "\n",
    "# transpose: è½¬ç½®\n",
    "z = torch.randn(2, 3, 4)\n",
    "print(f'\\nåŸå§‹å½¢çŠ¶: {z.shape}')\n",
    "print(f'transpose(0, 1) å: {z.transpose(0, 1).shape}')\n",
    "print(f'permute(2, 0, 1) å: {z.permute(2, 0, 1).shape}')\n",
    "\n",
    "# flatten: å±•å¹³\n",
    "flat = z.flatten()\n",
    "print(f'\\nflatten() å: å½¢çŠ¶ {flat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tensor-gpu",
   "metadata": {},
   "source": [
    "### 1.5 GPU åŠ é€Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gpu-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºå¼ é‡\n",
    "x_cpu = torch.randn(1000, 1000)\n",
    "print(f'CPU å¼ é‡è®¾å¤‡: {x_cpu.device}')\n",
    "\n",
    "# ç§»åŠ¨åˆ° GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰\n",
    "if torch.cuda.is_available():\n",
    "    x_gpu = x_cpu.to(device)\n",
    "    print(f'GPU å¼ é‡è®¾å¤‡: {x_gpu.device}')\n",
    "    \n",
    "    # æ€§èƒ½å¯¹æ¯”\n",
    "    import time\n",
    "    \n",
    "    # CPU è®¡ç®—\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        _ = x_cpu @ x_cpu\n",
    "    cpu_time = time.time() - start\n",
    "    \n",
    "    # GPU è®¡ç®—\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        _ = x_gpu @ x_gpu\n",
    "    torch.cuda.synchronize()  # ç­‰å¾… GPU å®Œæˆ\n",
    "    gpu_time = time.time() - start\n",
    "    \n",
    "    print(f'\\nCPU æ—¶é—´: {cpu_time:.4f}s')\n",
    "    print(f'GPU æ—¶é—´: {gpu_time:.4f}s')\n",
    "    print(f'åŠ é€Ÿæ¯”: {cpu_time / gpu_time:.2f}x')\n",
    "else:\n",
    "    print('GPU ä¸å¯ç”¨ï¼Œè·³è¿‡æ€§èƒ½å¯¹æ¯”')\n",
    "\n",
    "# CPU/GPU ä¹‹é—´è½¬æ¢\n",
    "print(f'\\nè½¬æ¢ç¤ºä¾‹:')\n",
    "x = torch.randn(3, 3).to(device)  # åˆ›å»ºå¹¶ç§»åŠ¨åˆ°è®¾å¤‡\n",
    "y = x.cpu()  # ç§»å› CPU\n",
    "z = y.numpy()  # è½¬æ¢ä¸º NumPyï¼ˆåªèƒ½åœ¨ CPU ä¸Šï¼‰\n",
    "print(f'x è®¾å¤‡: {x.device}')\n",
    "print(f'y è®¾å¤‡: {y.device}')\n",
    "print(f'z ç±»å‹: {type(z)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬2éƒ¨åˆ†: è‡ªåŠ¨å¾®åˆ†ï¼ˆAutogradï¼‰\n",
    "\n",
    "PyTorch çš„ autograd æœºåˆ¶å¯ä»¥è‡ªåŠ¨è®¡ç®—æ¢¯åº¦ï¼Œæ˜¯è®­ç»ƒç¥ç»ç½‘ç»œçš„æ ¸å¿ƒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "autograd-basics",
   "metadata": {},
   "source": [
    "### 2.1 æ¢¯åº¦è®¡ç®—åŸºç¡€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grad-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºéœ€è¦æ¢¯åº¦çš„å¼ é‡\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "print(f'x = {x}')\n",
    "print(f'requires_grad: {x.requires_grad}')\n",
    "\n",
    "# å‰å‘ä¼ æ’­ï¼šå®šä¹‰è®¡ç®—å›¾\n",
    "y = x ** 2 + 3 * x + 1\n",
    "print(f'\\ny = x^2 + 3x + 1 = {y}')\n",
    "\n",
    "# åå‘ä¼ æ’­ï¼šè®¡ç®—æ¢¯åº¦\n",
    "y.backward()\n",
    "print(f'\\ndy/dx = 2x + 3 = {x.grad}')\n",
    "print(f'åœ¨ x=2 æ—¶ï¼Œdy/dx = {x.grad.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "autograd-vector",
   "metadata": {},
   "source": [
    "### 2.2 å‘é‡ä¸çŸ©é˜µçš„æ¢¯åº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grad-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‘é‡æ¢¯åº¦\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "z = y.sum()  # æ ‡é‡è¾“å‡º\n",
    "\n",
    "z.backward()\n",
    "print(f'x = {x.data}')\n",
    "print(f'y = x^2 = {y.data}')\n",
    "print(f'z = sum(y) = {z.data}')\n",
    "print(f'dz/dx = 2x = {x.grad}')\n",
    "\n",
    "# çŸ©é˜µæ¢¯åº¦\n",
    "A = torch.tensor([[1.0, 2.0], [3.0, 4.0]], requires_grad=True)\n",
    "B = (A ** 2).sum()\n",
    "\n",
    "B.backward()\n",
    "print(f'\\nA:\\n{A.data}')\n",
    "print(f'dB/dA = 2A:\\n{A.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "autograd-computation-graph",
   "metadata": {},
   "source": [
    "### 2.3 è®¡ç®—å›¾ä¸é“¾å¼æ³•åˆ™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chain-rule",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¤šæ­¥è®¡ç®—\n",
    "x = torch.tensor([3.0], requires_grad=True)\n",
    "\n",
    "# y = 2x\n",
    "y = 2 * x\n",
    "print(f'y = 2x = {y.data}')\n",
    "\n",
    "# z = y^2 = (2x)^2 = 4x^2\n",
    "z = y ** 2\n",
    "print(f'z = y^2 = {z.data}')\n",
    "\n",
    "# w = z + 1 = 4x^2 + 1\n",
    "w = z + 1\n",
    "print(f'w = z + 1 = {w.data}')\n",
    "\n",
    "# åå‘ä¼ æ’­\n",
    "w.backward()\n",
    "\n",
    "# ç†è®ºæ¢¯åº¦ï¼šdw/dx = d(4x^2 + 1)/dx = 8x = 8*3 = 24\n",
    "print(f'\\ndw/dx = 8x = {x.grad}')\n",
    "print(f'ç†è®ºå€¼ = 8 * 3 = 24')\n",
    "\n",
    "# é“¾å¼æ³•åˆ™æ¼”ç¤º\n",
    "print(f'\\né“¾å¼æ³•åˆ™:')\n",
    "print(f'dw/dx = (dw/dz) * (dz/dy) * (dy/dx)')\n",
    "print(f'      = 1 * 2y * 2')\n",
    "print(f'      = 2 * 2 * (2x)')\n",
    "print(f'      = 8x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "autograd-control",
   "metadata": {},
   "source": [
    "### 2.4 æ¢¯åº¦æ§åˆ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grad-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. åœæ­¢æ¢¯åº¦è¿½è¸ª\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "\n",
    "# detach() ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»\n",
    "y_detached = y.detach()\n",
    "z = y_detached * 3\n",
    "\n",
    "print(f'y.requires_grad: {y.requires_grad}')\n",
    "print(f'y_detached.requires_grad: {y_detached.requires_grad}')\n",
    "print(f'z.requires_grad: {z.requires_grad}')\n",
    "\n",
    "# 2. torch.no_grad() ä¸Šä¸‹æ–‡ç®¡ç†å™¨\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x ** 2\n",
    "    print(f'\\nåœ¨ no_grad ä¸­ï¼Œy.requires_grad: {y.requires_grad}')\n",
    "\n",
    "# 3. æ¸…é›¶æ¢¯åº¦\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "for i in range(3):\n",
    "    y = x ** 2\n",
    "    y.backward()\n",
    "    print(f'è¿­ä»£ {i+1}, x.grad: {x.grad}')\n",
    "    x.grad.zero_()  # æ¸…é›¶æ¢¯åº¦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "autograd-visualization",
   "metadata": {},
   "source": [
    "### 2.5 æ¢¯åº¦å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grad-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å‡½æ•°åŠå…¶æ¢¯åº¦\n",
    "def visualize_gradient(func, func_name, x_range=(-3, 3)):\n",
    "    \"\"\"å¯è§†åŒ–å‡½æ•°åŠå…¶æ¢¯åº¦\"\"\"\n",
    "    x_vals = torch.linspace(x_range[0], x_range[1], 100, requires_grad=True)\n",
    "    y_vals = func(x_vals)\n",
    "    \n",
    "    # è®¡ç®—æ¢¯åº¦\n",
    "    y_vals.backward(torch.ones_like(y_vals))\n",
    "    grad_vals = x_vals.grad\n",
    "    \n",
    "    # ç»˜å›¾\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # å‡½æ•°æ›²çº¿\n",
    "    ax1.plot(x_vals.detach().numpy(), y_vals.detach().numpy(), linewidth=2)\n",
    "    ax1.set_xlabel('x', fontsize=12)\n",
    "    ax1.set_ylabel('f(x)', fontsize=12)\n",
    "    ax1.set_title(f'å‡½æ•°: {func_name}', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # æ¢¯åº¦æ›²çº¿\n",
    "    ax2.plot(x_vals.detach().numpy(), grad_vals.numpy(), color='red', linewidth=2)\n",
    "    ax2.set_xlabel('x', fontsize=12)\n",
    "    ax2.set_ylabel(\"f'(x)\", fontsize=12)\n",
    "    ax2.set_title(f'æ¢¯åº¦: d/dx({func_name})', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ç¤ºä¾‹1: y = x^2\n",
    "visualize_gradient(lambda x: x ** 2, 'xÂ²')\n",
    "\n",
    "# ç¤ºä¾‹2: y = sin(x)\n",
    "visualize_gradient(lambda x: torch.sin(x), 'sin(x)')\n",
    "\n",
    "# ç¤ºä¾‹3: y = x^3 - 3x^2 + 2\n",
    "visualize_gradient(lambda x: x ** 3 - 3 * x ** 2 + 2, 'xÂ³ - 3xÂ² + 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬3éƒ¨åˆ†: ç¥ç»ç½‘ç»œæ¨¡å—ï¼ˆnn.Moduleï¼‰\n",
    "\n",
    "PyTorch æä¾›äº† `nn.Module` ç±»æ¥æ„å»ºç¥ç»ç½‘ç»œï¼Œä»¥åŠå„ç§é¢„å®šä¹‰çš„å±‚å’ŒæŸå¤±å‡½æ•°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn-layers",
   "metadata": {},
   "source": [
    "### 3.1 å¸¸ç”¨å±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-layers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. å…¨è¿æ¥å±‚ï¼ˆLinearï¼‰\n",
    "linear = nn.Linear(in_features=10, out_features=5)\n",
    "x = torch.randn(3, 10)  # batch_size=3, features=10\n",
    "output = linear(x)\n",
    "print(f'Linear å±‚:')\n",
    "print(f'  è¾“å…¥å½¢çŠ¶: {x.shape}')\n",
    "print(f'  è¾“å‡ºå½¢çŠ¶: {output.shape}')\n",
    "print(f'  æƒé‡å½¢çŠ¶: {linear.weight.shape}')\n",
    "print(f'  åç½®å½¢çŠ¶: {linear.bias.shape}')\n",
    "\n",
    "# 2. å·ç§¯å±‚ï¼ˆConv2dï¼‰\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "x = torch.randn(8, 3, 32, 32)  # batch_size=8, channels=3, height=32, width=32\n",
    "output = conv(x)\n",
    "print(f'\\nConv2d å±‚:')\n",
    "print(f'  è¾“å…¥å½¢çŠ¶: {x.shape}')\n",
    "print(f'  è¾“å‡ºå½¢çŠ¶: {output.shape}')\n",
    "\n",
    "# 3. æ± åŒ–å±‚ï¼ˆMaxPool2dï¼‰\n",
    "pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "output_pooled = pool(output)\n",
    "print(f'\\nMaxPool2d å±‚:')\n",
    "print(f'  è¾“å…¥å½¢çŠ¶: {output.shape}')\n",
    "print(f'  è¾“å‡ºå½¢çŠ¶: {output_pooled.shape}')\n",
    "\n",
    "# 4. Batch Normalization\n",
    "bn = nn.BatchNorm2d(16)\n",
    "output_bn = bn(output)\n",
    "print(f'\\nBatchNorm2d å±‚:')\n",
    "print(f'  è¾“å…¥å½¢çŠ¶: {output.shape}')\n",
    "print(f'  è¾“å‡ºå½¢çŠ¶: {output_bn.shape}')\n",
    "\n",
    "# 5. Dropout\n",
    "dropout = nn.Dropout(p=0.5)\n",
    "x = torch.ones(10)\n",
    "output_dropout = dropout(x)\n",
    "print(f'\\nDropout å±‚ (è®­ç»ƒæ¨¡å¼):')\n",
    "print(f'  è¾“å…¥: {x}')\n",
    "print(f'  è¾“å‡º: {output_dropout}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn-activations",
   "metadata": {},
   "source": [
    "### 3.2 æ¿€æ´»å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¸¸ç”¨æ¿€æ´»å‡½æ•°\n",
    "x = torch.linspace(-5, 5, 100)\n",
    "\n",
    "activations = {\n",
    "    'ReLU': F.relu(x),\n",
    "    'Sigmoid': torch.sigmoid(x),\n",
    "    'Tanh': torch.tanh(x),\n",
    "    'LeakyReLU': F.leaky_relu(x, 0.1)\n",
    "}\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (name, y) in enumerate(activations.items()):\n",
    "    axes[idx].plot(x.numpy(), y.numpy(), linewidth=2)\n",
    "    axes[idx].set_xlabel('x', fontsize=12)\n",
    "    axes[idx].set_ylabel('f(x)', fontsize=12)\n",
    "    axes[idx].set_title(name, fontsize=14)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "    axes[idx].axvline(x=0, color='k', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn-model",
   "metadata": {},
   "source": [
    "### 3.3 æ„å»ºç¥ç»ç½‘ç»œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"ç®€å•çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œ\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        \n",
    "        # å®šä¹‰å±‚\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"å‰å‘ä¼ æ’­\"\"\"\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "model = SimpleNN(input_size=784, hidden_size=128, output_size=10)\n",
    "print(model)\n",
    "\n",
    "# æµ‹è¯•å‰å‘ä¼ æ’­\n",
    "x = torch.randn(32, 784)  # batch_size=32\n",
    "output = model(x)\n",
    "print(f'\\nè¾“å…¥å½¢çŠ¶: {x.shape}')\n",
    "print(f'è¾“å‡ºå½¢çŠ¶: {output.shape}')\n",
    "\n",
    "# æŸ¥çœ‹å‚æ•°\n",
    "print(f'\\næ¨¡å‹å‚æ•°:')\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'  {name}: {param.shape}, requires_grad={param.requires_grad}')\n",
    "\n",
    "# è®¡ç®—æ€»å‚æ•°é‡\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'\\næ€»å‚æ•°é‡: {total_params:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn-sequential",
   "metadata": {},
   "source": [
    "### 3.4 ä½¿ç”¨ Sequential æ„å»ºæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sequential-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ Sequential æ„å»ºç›¸åŒçš„æ¨¡å‹\n",
    "model_seq = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")\n",
    "\n",
    "print('Sequential æ¨¡å‹:')\n",
    "print(model_seq)\n",
    "\n",
    "# æ›´å¤æ‚çš„ç¤ºä¾‹\n",
    "model_complex = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(128, 10)\n",
    ")\n",
    "\n",
    "print('\\nå¤æ‚ Sequential æ¨¡å‹:')\n",
    "print(model_complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn-loss",
   "metadata": {},
   "source": [
    "### 3.5 æŸå¤±å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loss-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. äº¤å‰ç†µæŸå¤±ï¼ˆåˆ†ç±»ï¼‰\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "predictions = torch.randn(5, 3)  # 5ä¸ªæ ·æœ¬ï¼Œ3ä¸ªç±»åˆ«\n",
    "targets = torch.tensor([0, 1, 2, 1, 0])  # çœŸå®æ ‡ç­¾\n",
    "loss_ce = criterion_ce(predictions, targets)\n",
    "print(f'CrossEntropyLoss: {loss_ce.item():.4f}')\n",
    "\n",
    "# 2. MSE æŸå¤±ï¼ˆå›å½’ï¼‰\n",
    "criterion_mse = nn.MSELoss()\n",
    "predictions = torch.randn(5, 1)\n",
    "targets = torch.randn(5, 1)\n",
    "loss_mse = criterion_mse(predictions, targets)\n",
    "print(f'MSELoss: {loss_mse.item():.4f}')\n",
    "\n",
    "# 3. BCE æŸå¤±ï¼ˆäºŒåˆ†ç±»ï¼‰\n",
    "criterion_bce = nn.BCEWithLogitsLoss()\n",
    "predictions = torch.randn(5, 1)\n",
    "targets = torch.randint(0, 2, (5, 1)).float()\n",
    "loss_bce = criterion_bce(predictions, targets)\n",
    "print(f'BCEWithLogitsLoss: {loss_bce.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬4éƒ¨åˆ†: ä¼˜åŒ–å™¨ä¸è®­ç»ƒ\n",
    "\n",
    "ä¼˜åŒ–å™¨è´Ÿè´£æ ¹æ®æ¢¯åº¦æ›´æ–°æ¨¡å‹å‚æ•°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimizers",
   "metadata": {},
   "source": [
    "### 4.1 å¸¸ç”¨ä¼˜åŒ–å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-optimizers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ¨¡å‹\n",
    "model = SimpleNN(784, 128, 10)\n",
    "\n",
    "# 1. SGDï¼ˆéšæœºæ¢¯åº¦ä¸‹é™ï¼‰\n",
    "optimizer_sgd = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "print('SGD ä¼˜åŒ–å™¨:')\n",
    "print(optimizer_sgd)\n",
    "\n",
    "# 2. Adam\n",
    "optimizer_adam = optim.Adam(model.parameters(), lr=0.001)\n",
    "print('\\nAdam ä¼˜åŒ–å™¨:')\n",
    "print(optimizer_adam)\n",
    "\n",
    "# 3. RMSprop\n",
    "optimizer_rmsprop = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "print('\\nRMSprop ä¼˜åŒ–å™¨:')\n",
    "print(optimizer_rmsprop)\n",
    "\n",
    "# ä¸åŒå­¦ä¹ ç‡\n",
    "optimizer_groups = optim.Adam([\n",
    "    {'params': model.fc1.parameters(), 'lr': 0.001},\n",
    "    {'params': model.fc2.parameters(), 'lr': 0.01}\n",
    "])\n",
    "print('\\nä¸åŒå±‚ä½¿ç”¨ä¸åŒå­¦ä¹ ç‡:')\n",
    "print(optimizer_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lr-scheduler",
   "metadata": {},
   "source": [
    "### 4.2 å­¦ä¹ ç‡è°ƒåº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learning-rate-scheduler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºä¼˜åŒ–å™¨\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# 1. StepLR: æ¯ step_size ä¸ª epochï¼Œlr *= gamma\n",
    "scheduler_step = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "# 2. MultiStepLR: åœ¨æŒ‡å®š epochï¼Œlr *= gamma\n",
    "scheduler_multistep = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20, 30], gamma=0.1)\n",
    "\n",
    "# 3. ExponentialLR: lr *= gamma^epoch\n",
    "scheduler_exp = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "# 4. CosineAnnealingLR: ä½™å¼¦é€€ç«\n",
    "scheduler_cosine = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "# å¯è§†åŒ–å­¦ä¹ ç‡å˜åŒ–\n",
    "def visualize_lr_schedule(scheduler, epochs=50):\n",
    "    lrs = []\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "    \n",
    "    if scheduler == 'step':\n",
    "        sched = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "        title = 'StepLR (step_size=10, gamma=0.5)'\n",
    "    elif scheduler == 'exp':\n",
    "        sched = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "        title = 'ExponentialLR (gamma=0.95)'\n",
    "    elif scheduler == 'cosine':\n",
    "        sched = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "        title = f'CosineAnnealingLR (T_max={epochs})'\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "        sched.step()\n",
    "    \n",
    "    return lrs, title\n",
    "\n",
    "# ç»˜åˆ¶å¯¹æ¯”å›¾\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, sched_type in enumerate(['step', 'exp', 'cosine']):\n",
    "    lrs, title = visualize_lr_schedule(sched_type)\n",
    "    axes[idx].plot(lrs, linewidth=2)\n",
    "    axes[idx].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[idx].set_ylabel('Learning Rate', fontsize=12)\n",
    "    axes[idx].set_title(title, fontsize=12)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬5éƒ¨åˆ†: å®Œæ•´è®­ç»ƒæµç¨‹\n",
    "\n",
    "å°†æ‰€æœ‰ç»„ä»¶æ•´åˆï¼Œå®ç°å®Œæ•´çš„è®­ç»ƒå’Œè¯„ä¼°æµç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mnist-data",
   "metadata": {},
   "source": [
    "### 5.1 æ•°æ®å‡†å¤‡ï¼šMNIST æ‰‹å†™æ•°å­—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-mnist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®å˜æ¢\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# ä¸‹è½½å¹¶åŠ è½½æ•°æ®\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(f'è®­ç»ƒé›†å¤§å°: {len(train_dataset)}')\n",
    "print(f'æµ‹è¯•é›†å¤§å°: {len(test_dataset)}')\n",
    "print(f'å›¾åƒå½¢çŠ¶: {train_dataset[0][0].shape}')\n",
    "\n",
    "# å¯è§†åŒ–éƒ¨åˆ†æ•°æ®\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(16):\n",
    "    image, label = train_dataset[i]\n",
    "    axes[i].imshow(image.squeeze(), cmap='gray')\n",
    "    axes[i].set_title(f'æ ‡ç­¾: {label}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('MNIST è®­ç»ƒæ•°æ®æ ·æœ¬', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mnist-model",
   "metadata": {},
   "source": [
    "### 5.2 å®šä¹‰æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-mnist-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    \"\"\"MNIST åˆ†ç±»ç½‘ç»œ\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "model = MNISTNet().to(device)\n",
    "print(model)\n",
    "\n",
    "# å‚æ•°ç»Ÿè®¡\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'\\næ€»å‚æ•°é‡: {total_params:,}')\n",
    "print(f'å¯è®­ç»ƒå‚æ•°: {trainable_params:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-function",
   "metadata": {},
   "source": [
    "### 5.3 è®­ç»ƒä¸è¯„ä¼°å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-eval-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"è®­ç»ƒä¸€ä¸ª epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='è®­ç»ƒ', leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # å‰å‘ä¼ æ’­\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # åå‘ä¼ æ’­\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # ç»Ÿè®¡\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # æ›´æ–°è¿›åº¦æ¡\n",
    "        pbar.set_postfix({\n",
    "            'loss': running_loss / total,\n",
    "            'acc': 100. * correct / total\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"è¯„ä¼°æ¨¡å‹\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, \n",
    "                scheduler=None, epochs=10, device='cpu'):\n",
    "    \"\"\"å®Œæ•´è®­ç»ƒæµç¨‹\"\"\"\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # è®­ç»ƒ\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # è¯„ä¼°\n",
    "        test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "        \n",
    "        # å­¦ä¹ ç‡è°ƒåº¦\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # è®°å½•å†å²\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        \n",
    "        # æ‰“å°è¿›åº¦\n",
    "        print(f'Epoch {epoch+1}/{epochs}: '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
    "              f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-model",
   "metadata": {},
   "source": [
    "### 5.4 å¼€å§‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "start-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "print('å¼€å§‹è®­ç»ƒ...')\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    epochs=10,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print('\\nè®­ç»ƒå®Œæˆ!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-results",
   "metadata": {},
   "source": [
    "### 5.5 å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# æŸå¤±æ›²çº¿\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "ax1.plot(epochs, history['train_loss'], 'o-', label='è®­ç»ƒæŸå¤±', linewidth=2)\n",
    "ax1.plot(epochs, history['test_loss'], 's-', label='æµ‹è¯•æŸå¤±', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('æŸå¤±', fontsize=12)\n",
    "ax1.set_title('æŸå¤±æ›²çº¿', fontsize=14)\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# å‡†ç¡®ç‡æ›²çº¿\n",
    "ax2.plot(epochs, history['train_acc'], 'o-', label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2)\n",
    "ax2.plot(epochs, history['test_acc'], 's-', label='æµ‹è¯•å‡†ç¡®ç‡', linewidth=2)\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('å‡†ç¡®ç‡ (%)', fontsize=12)\n",
    "ax2.set_title('å‡†ç¡®ç‡æ›²çº¿', fontsize=14)\n",
    "ax2.legend(fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\næœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {history[\"test_acc\"][-1]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-predictions",
   "metadata": {},
   "source": [
    "### 5.6 é¢„æµ‹å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è·å–ä¸€æ‰¹æµ‹è¯•æ•°æ®\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "images = images[:16]\n",
    "labels = labels[:16]\n",
    "\n",
    "# é¢„æµ‹\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(images.to(device))\n",
    "    _, predicted = outputs.max(1)\n",
    "    predicted = predicted.cpu()\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(16):\n",
    "    axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "    title = f'çœŸå®: {labels[i]} | é¢„æµ‹: {predicted[i]}'\n",
    "    color = 'green' if labels[i] == predicted[i] else 'red'\n",
    "    axes[i].set_title(title, color=color)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('MNIST é¢„æµ‹ç»“æœï¼ˆç»¿è‰²=æ­£ç¡®ï¼Œçº¢è‰²=é”™è¯¯ï¼‰', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-load",
   "metadata": {},
   "source": [
    "### 5.7 æ¨¡å‹ä¿å­˜ä¸åŠ è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜æ¨¡å‹\n",
    "torch.save({\n",
    "    'epoch': 10,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': history['test_loss'][-1],\n",
    "    'accuracy': history['test_acc'][-1]\n",
    "}, 'mnist_model.pth')\n",
    "\n",
    "print('æ¨¡å‹å·²ä¿å­˜åˆ° mnist_model.pth')\n",
    "\n",
    "# åŠ è½½æ¨¡å‹\n",
    "checkpoint = torch.load('mnist_model.pth')\n",
    "model_loaded = MNISTNet().to(device)\n",
    "model_loaded.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(f'\\næ¨¡å‹å·²åŠ è½½')\n",
    "print(f'è®­ç»ƒè½®æ•°: {checkpoint[\"epoch\"]}')\n",
    "print(f'æµ‹è¯•æŸå¤±: {checkpoint[\"loss\"]:.4f}')\n",
    "print(f'æµ‹è¯•å‡†ç¡®ç‡: {checkpoint[\"accuracy\"]:.2f}%')\n",
    "\n",
    "# éªŒè¯åŠ è½½çš„æ¨¡å‹\n",
    "test_loss, test_acc = evaluate(model_loaded, test_loader, criterion, device)\n",
    "print(f'\\néªŒè¯åŠ è½½æ¨¡å‹çš„å‡†ç¡®ç‡: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ æ€»ç»“\n",
    "\n",
    "é€šè¿‡æœ¬ Notebookï¼Œæˆ‘ä»¬å…¨é¢å­¦ä¹ äº† PyTorch çš„æ ¸å¿ƒæ¦‚å¿µï¼š\n",
    "\n",
    "### ç¬¬1éƒ¨åˆ†: å¼ é‡åŸºç¡€ âœ…\n",
    "- åˆ›å»ºå¼ é‡çš„å¤šç§æ–¹å¼ï¼ˆä»åˆ—è¡¨ã€NumPyã€ç‰¹æ®Šå¼ é‡ï¼‰\n",
    "- å¼ é‡æ“ä½œï¼ˆç®—æœ¯ã€çŸ©é˜µè¿ç®—ã€èšåˆï¼‰\n",
    "- ç´¢å¼•ä¸åˆ‡ç‰‡ï¼ˆå¸ƒå°”ç´¢å¼•ã€å¤šç»´ç´¢å¼•ï¼‰\n",
    "- å½¢çŠ¶å˜æ¢ï¼ˆreshapeã€viewã€unsqueezeã€squeezeã€transposeï¼‰\n",
    "- GPU åŠ é€Ÿï¼ˆCPU/GPU æ•°æ®è½¬æ¢ã€æ€§èƒ½å¯¹æ¯”ï¼‰\n",
    "\n",
    "### ç¬¬2éƒ¨åˆ†: è‡ªåŠ¨å¾®åˆ† âœ…\n",
    "- æ¢¯åº¦è®¡ç®—åŸºç¡€ï¼ˆrequires_gradã€backwardï¼‰\n",
    "- å‘é‡ä¸çŸ©é˜µçš„æ¢¯åº¦\n",
    "- è®¡ç®—å›¾ä¸é“¾å¼æ³•åˆ™\n",
    "- æ¢¯åº¦æ§åˆ¶ï¼ˆdetachã€no_gradã€é›¶æ¢¯åº¦ï¼‰\n",
    "- æ¢¯åº¦å¯è§†åŒ–\n",
    "\n",
    "### ç¬¬3éƒ¨åˆ†: ç¥ç»ç½‘ç»œæ¨¡å— âœ…\n",
    "- å¸¸ç”¨å±‚ï¼ˆLinearã€Conv2dã€MaxPool2dã€BatchNormã€Dropoutï¼‰\n",
    "- æ¿€æ´»å‡½æ•°ï¼ˆReLUã€Sigmoidã€Tanhã€LeakyReLUï¼‰\n",
    "- æ„å»ºç¥ç»ç½‘ç»œï¼ˆnn.Moduleã€Sequentialï¼‰\n",
    "- æŸå¤±å‡½æ•°ï¼ˆCrossEntropyLossã€MSELossã€BCELossï¼‰\n",
    "\n",
    "### ç¬¬4éƒ¨åˆ†: ä¼˜åŒ–å™¨ âœ…\n",
    "- å¸¸ç”¨ä¼˜åŒ–å™¨ï¼ˆSGDã€Adamã€RMSpropï¼‰\n",
    "- å­¦ä¹ ç‡è°ƒåº¦ï¼ˆStepLRã€ExponentialLRã€CosineAnnealingLRï¼‰\n",
    "\n",
    "### ç¬¬5éƒ¨åˆ†: å®Œæ•´è®­ç»ƒæµç¨‹ âœ…\n",
    "- æ•°æ®åŠ è½½ï¼ˆMNIST æ•°æ®é›†ï¼‰\n",
    "- æ¨¡å‹å®šä¹‰\n",
    "- è®­ç»ƒä¸è¯„ä¼°å‡½æ•°\n",
    "- è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–\n",
    "- é¢„æµ‹ç»“æœå±•ç¤º\n",
    "- æ¨¡å‹ä¿å­˜ä¸åŠ è½½\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ å…³é”®è¦ç‚¹\n",
    "\n",
    "1. **å¼ é‡æ˜¯ PyTorch çš„åŸºçŸ³**: ç±»ä¼¼ NumPyï¼Œä½†æ”¯æŒ GPU åŠ é€Ÿå’Œè‡ªåŠ¨å¾®åˆ†\n",
    "2. **autograd è‡ªåŠ¨è®¡ç®—æ¢¯åº¦**: æ— éœ€æ‰‹åŠ¨æ¨å¯¼ï¼Œè‡ªåŠ¨æ‰§è¡Œåå‘ä¼ æ’­\n",
    "3. **nn.Module æ˜¯æ¨¡å‹åŸºç±»**: é€šè¿‡ç»§æ‰¿æ„å»ºè‡ªå®šä¹‰ç½‘ç»œ\n",
    "4. **è®­ç»ƒå¾ªç¯**: å‰å‘ä¼ æ’­ â†’ è®¡ç®—æŸå¤± â†’ åå‘ä¼ æ’­ â†’ æ›´æ–°å‚æ•°\n",
    "5. **GPU åŠ é€Ÿ**: ä½¿ç”¨ `.to(device)` å°†å¼ é‡å’Œæ¨¡å‹ç§»åˆ° GPU\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š ä¸‹ä¸€æ­¥\n",
    "\n",
    "- ğŸ¯ æ·±å…¥å­¦ä¹  CNNï¼š[03-cnn-image-classification.ipynb](03-cnn-image-classification.ipynb)\n",
    "- ğŸ“– æ¢ç´¢ RNNï¼š[04-rnn-text-classification.ipynb](04-rnn-text-classification.ipynb)\n",
    "- ğŸš€ å®æˆ˜é¡¹ç›®ï¼š[Stage 4 æ·±åº¦å­¦ä¹ é¡¹ç›®](../../docs/stage4/projects/)\n",
    "\n",
    "---\n",
    "\n",
    "**ç»ƒä¹ å»ºè®®**:\n",
    "1. ä¿®æ”¹ MNIST æ¨¡å‹æ¶æ„ï¼Œå°è¯•ä¸åŒçš„å±‚æ•°å’Œç¥ç»å…ƒæ•°é‡\n",
    "2. å°è¯•ä¸åŒçš„ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡ï¼Œè§‚å¯Ÿæ”¶æ•›é€Ÿåº¦\n",
    "3. å®ç°æ•°æ®å¢å¼ºï¼ˆæ—‹è½¬ã€ç¼©æ”¾ã€å™ªå£°ï¼‰\n",
    "4. æ·»åŠ æ—©åœï¼ˆEarly Stoppingï¼‰æœºåˆ¶\n",
    "5. å¯è§†åŒ–æƒé‡åˆ†å¸ƒå’Œæ¢¯åº¦æµ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
