# æ¨¡å—M02: è®¡ç®—æœºè§†è§‰åŸºç¡€

**é˜¶æ®µ**: Stage 4 - æ·±åº¦å­¦ä¹ 
**é¢„è®¡å­¦ä¹ æ—¶é—´**: 3-4å°æ—¶ï¼ˆç†è®ºï¼‰+ 3-4å°æ—¶ï¼ˆå®è·µï¼‰
**éš¾åº¦**: â­â­â­â­ ä¸­é«˜ç­‰

---

## ğŸ“š å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬æ¨¡å—åï¼Œä½ å°†èƒ½å¤Ÿï¼š

- âœ… ç†è§£å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„æ ¸å¿ƒåŸç†ä¸æ¶æ„è®¾è®¡
- âœ… æŒæ¡å·ç§¯å±‚ã€æ± åŒ–å±‚ã€å…¨è¿æ¥å±‚çš„ä½œç”¨ä¸è®¡ç®—è¿‡ç¨‹
- âœ… ç†Ÿæ‚‰ç»å…¸CNNæ¶æ„ï¼ˆLeNetã€AlexNetã€VGGã€ResNetã€EfficientNetï¼‰
- âœ… ç†è§£ç›®æ ‡æ£€æµ‹çš„æ ¸å¿ƒæ¦‚å¿µï¼ˆYOLOã€Faster R-CNNã€DETRï¼‰
- âœ… æŒæ¡å›¾åƒåˆ†å‰²æŠ€æœ¯ï¼ˆU-Netã€Mask R-CNNã€Segment Anythingï¼‰
- âœ… èƒ½å¤Ÿä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œè¿ç§»å­¦ä¹ ä¸æ¨¡å‹å¾®è°ƒ

---

## ğŸ¯ æ ¸å¿ƒçŸ¥è¯†ç‚¹

### 1. å·ç§¯ç¥ç»ç½‘ç»œ (CNN) åŸºç¡€

#### 1.1 ä¸ºä»€ä¹ˆéœ€è¦ CNNï¼Ÿ

ä¼ ç»Ÿçš„å…¨è¿æ¥ç¥ç»ç½‘ç»œåœ¨å¤„ç†å›¾åƒæ—¶å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

**é—®é¢˜ç¤ºä¾‹**ï¼š
```
è¾“å…¥å›¾åƒ: 224Ã—224Ã—3 (RGB) = 150,528 åƒç´ 
å…¨è¿æ¥å±‚: 150,528 Ã— 1000 = 1.5äº¿ä¸ªå‚æ•°ï¼
```

**CNN çš„ä¸‰å¤§ä¼˜åŠ¿**ï¼š
1. **å‚æ•°å…±äº«** (Parameter Sharing): åŒä¸€ä¸ªå·ç§¯æ ¸åœ¨æ•´ä¸ªå›¾åƒä¸Šæ»‘åŠ¨
2. **å±€éƒ¨è¿æ¥** (Local Connectivity): æ¯ä¸ªç¥ç»å…ƒåªè¿æ¥å±€éƒ¨åŒºåŸŸ
3. **å¹³ç§»ä¸å˜æ€§** (Translation Invariance): å¯¹ç‰©ä½“ä½ç½®ä¸æ•æ„Ÿ

#### 1.2 å·ç§¯å±‚ (Convolutional Layer)

å·ç§¯æ“ä½œæ˜¯ CNN çš„æ ¸å¿ƒï¼Œç”¨äºæå–å›¾åƒç‰¹å¾ã€‚

**æ•°å­¦å®šä¹‰**:
```
Output[i,j] = Î£ Î£ Input[i+m, j+n] Â· Kernel[m,n] + bias
             m n
```

**å‚æ•°è¯´æ˜**ï¼š
- `Kernel Size`: å·ç§¯æ ¸å¤§å°ï¼ˆå¸¸ç”¨ 3Ã—3, 5Ã—5, 7Ã—7ï¼‰
- `Stride`: æ­¥é•¿ï¼ˆé»˜è®¤1ï¼Œå½±å“è¾“å‡ºå°ºå¯¸ï¼‰
- `Padding`: å¡«å……ï¼ˆ'SAME'ä¿æŒå°ºå¯¸ï¼Œ'VALID'ä¸å¡«å……ï¼‰
- `Channels`: è¾“å…¥/è¾“å‡ºé€šé“æ•°

**è¾“å‡ºå°ºå¯¸è®¡ç®—**:
```
Output_height = (Input_height - Kernel_height + 2 Ã— Padding) / Stride + 1
Output_width  = (Input_width  - Kernel_width  + 2 Ã— Padding) / Stride + 1
```

**ç¤ºä¾‹**ï¼š
```python
import torch.nn as nn

# è¾“å…¥: (batch_size, 3, 224, 224)
conv = nn.Conv2d(
    in_channels=3,      # RGB 3é€šé“
    out_channels=64,    # è¾“å‡º64ä¸ªç‰¹å¾å›¾
    kernel_size=3,      # 3Ã—3å·ç§¯æ ¸
    stride=1,           # æ­¥é•¿1
    padding=1           # å¡«å……1ï¼ˆä¿æŒå°ºå¯¸ï¼‰
)
# è¾“å‡º: (batch_size, 64, 224, 224)
```

**ç‰¹å¾æå–å±‚æ¬¡**ï¼š
- **æµ…å±‚å·ç§¯**: æ£€æµ‹è¾¹ç¼˜ã€è§’ç‚¹ã€çº¹ç†
- **ä¸­å±‚å·ç§¯**: æ£€æµ‹å½¢çŠ¶ã€éƒ¨ä»¶ï¼ˆçœ¼ç›ã€è½®å­ï¼‰
- **æ·±å±‚å·ç§¯**: æ£€æµ‹å¤æ‚å¯¹è±¡ï¼ˆäººè„¸ã€æ±½è½¦ï¼‰

**å¯è§†åŒ–**ï¼šå‚è§ `notebooks/stage4/03-cnn-image-classification.ipynb` ç¬¬1èŠ‚

#### 1.3 æ± åŒ–å±‚ (Pooling Layer)

æ± åŒ–ç”¨äºé™ä½ç‰¹å¾å›¾çš„ç©ºé—´ç»´åº¦ï¼Œå‡å°‘è®¡ç®—é‡å’Œè¿‡æ‹Ÿåˆã€‚

**ä¸¤ç§å¸¸ç”¨æ± åŒ–**ï¼š

| æ± åŒ–ç±»å‹ | æ“ä½œ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|---------|------|------|------|---------|
| **Max Pooling** | å–åŒºåŸŸæœ€å¤§å€¼ | ä¿ç•™æ˜¾è‘—ç‰¹å¾ã€é²æ£’æ€§å¼º | ä¸¢å¤±ä½ç½®ä¿¡æ¯ | ç›®æ ‡æ£€æµ‹ã€åˆ†ç±» |
| **Average Pooling** | å–åŒºåŸŸå¹³å‡å€¼ | å¹³æ»‘ç‰¹å¾ã€ä¿ç•™èƒŒæ™¯ | ç‰¹å¾ä¸æ˜æ˜¾ | å…¨å±€ç‰¹å¾æå– |

**ç¤ºä¾‹**ï¼š
```python
# Max Pooling (2Ã—2çª—å£ï¼Œstride=2)
maxpool = nn.MaxPool2d(kernel_size=2, stride=2)
# è¾“å…¥: (batch, 64, 224, 224)
# è¾“å‡º: (batch, 64, 112, 112)  # å°ºå¯¸å‡åŠ
```

#### 1.4 æ‰¹å½’ä¸€åŒ– (Batch Normalization)

æ‰¹å½’ä¸€åŒ–åŠ é€Ÿè®­ç»ƒã€æé«˜ç¨³å®šæ€§ã€‚

**å…¬å¼**:
```
BN(x) = Î³ Â· (x - Î¼) / âˆš(ÏƒÂ² + Îµ) + Î²
```
å…¶ä¸­ï¼š
- `Î¼`: æ‰¹æ¬¡å‡å€¼
- `ÏƒÂ²`: æ‰¹æ¬¡æ–¹å·®
- `Î³, Î²`: å¯å­¦ä¹ å‚æ•°
- `Îµ`: æ•°å€¼ç¨³å®šé¡¹ (é€šå¸¸1e-5)

**ä¼˜ç‚¹**ï¼š
- ç¼“è§£æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸
- å…è®¸æ›´å¤§å­¦ä¹ ç‡
- å‡å°‘å¯¹åˆå§‹åŒ–çš„ä¾èµ–
- ä¸€å®šç¨‹åº¦çš„æ­£åˆ™åŒ–æ•ˆæœ

**æ”¾ç½®ä½ç½®**ï¼š
```python
# æ¨èé¡ºåº: Conv â†’ BN â†’ Activation
conv = nn.Conv2d(3, 64, 3, padding=1)
bn = nn.BatchNorm2d(64)
relu = nn.ReLU()
# å‰å‘ä¼ æ’­: x â†’ conv(x) â†’ bn(x) â†’ relu(x)
```

---

### 2. ç»å…¸ CNN æ¶æ„æ¼”è¿›

#### 2.1 LeNet-5 (1998)

**å†å²æ„ä¹‰**: ç¬¬ä¸€ä¸ªæˆåŠŸçš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œç”¨äºæ‰‹å†™æ•°å­—è¯†åˆ«ï¼ˆMNISTï¼‰ã€‚

**ç½‘ç»œç»“æ„**:
```
è¾“å…¥(32Ã—32Ã—1)
  â†“
Conv(5Ã—5, 6) â†’ AvgPool(2Ã—2) â†’ Conv(5Ã—5, 16) â†’ AvgPool(2Ã—2)
  â†“
FC(120) â†’ FC(84) â†’ FC(10)
```

**å‚æ•°é‡**: ~60K
**ç‰¹ç‚¹**: ç®€å•ã€æ˜“è®­ç»ƒï¼Œç°ä»£æ ‡å‡†çœ‹å·²è¿‡æ—¶

#### 2.2 AlexNet (2012)

**å†å²æ„ä¹‰**: ImageNet 2012å† å†›ï¼Œå¼€å¯æ·±åº¦å­¦ä¹ æ—¶ä»£ã€‚

**å…³é”®åˆ›æ–°**ï¼š
1. ä½¿ç”¨ **ReLU** æ¿€æ´»å‡½æ•°ï¼ˆæ›¿ä»£Sigmoid/Tanhï¼‰
2. å¼•å…¥ **Dropout** æ­£åˆ™åŒ–ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
3. ä½¿ç”¨ **æ•°æ®å¢å¼º**ï¼ˆéšæœºè£å‰ªã€ç¿»è½¬ï¼‰
4. **GPUå¹¶è¡Œè®­ç»ƒ**ï¼ˆåŒGPUæ¶æ„ï¼‰

**ç½‘ç»œç»“æ„**:
```
è¾“å…¥(224Ã—224Ã—3)
  â†“
Conv(11Ã—11, 96, stride=4) â†’ MaxPool(3Ã—3, stride=2)
  â†“
Conv(5Ã—5, 256) â†’ MaxPool(3Ã—3, stride=2)
  â†“
Conv(3Ã—3, 384) â†’ Conv(3Ã—3, 384) â†’ Conv(3Ã—3, 256)
  â†“
MaxPool(3Ã—3, stride=2) â†’ FC(4096) â†’ Dropout(0.5)
  â†“
FC(4096) â†’ Dropout(0.5) â†’ FC(1000)
```

**å‚æ•°é‡**: ~60M
**ImageNet Top-5é”™è¯¯ç‡**: 15.3% (2012å¹´)

#### 2.3 VGG-16/19 (2014)

**æ ¸å¿ƒæ€æƒ³**: "æ›´æ·±" + "å°å·ç§¯æ ¸"ï¼ˆå…¨éƒ¨ç”¨3Ã—3ï¼‰

**ä¸ºä»€ä¹ˆç”¨å°å·ç§¯æ ¸ï¼Ÿ**
- 2ä¸ª3Ã—3å·ç§¯ = 1ä¸ª5Ã—5å·ç§¯ï¼ˆæ„Ÿå—é‡ç›¸åŒï¼‰
- ä½†å‚æ•°æ›´å°‘ï¼š2Ã—(3Ã—3) = 18 < 1Ã—(5Ã—5) = 25
- æ›´å¤šéçº¿æ€§ï¼ˆ2ä¸ªReLU vs 1ä¸ªReLUï¼‰

**VGG-16 ç»“æ„**:
```
è¾“å…¥(224Ã—224Ã—3)
  â†“
Conv3-64 Ã— 2 â†’ MaxPool
  â†“
Conv3-128 Ã— 2 â†’ MaxPool
  â†“
Conv3-256 Ã— 3 â†’ MaxPool
  â†“
Conv3-512 Ã— 3 â†’ MaxPool
  â†“
Conv3-512 Ã— 3 â†’ MaxPool
  â†“
FC(4096) â†’ FC(4096) â†’ FC(1000)
```

**å‚æ•°é‡**: VGG-16 ~138M, VGG-19 ~144M
**ImageNet Top-5é”™è¯¯ç‡**: 7.3%

**ç¼ºç‚¹**: å‚æ•°é‡å·¨å¤§ã€è®­ç»ƒæ…¢ã€æ˜¾å­˜å ç”¨é«˜

#### 2.4 ResNet (2015)

**æ ¸å¿ƒåˆ›æ–°**: **æ®‹å·®è¿æ¥ (Residual Connection)**ï¼Œè§£å†³æ·±å±‚ç½‘ç»œé€€åŒ–é—®é¢˜ã€‚

**æ®‹å·®å— (Residual Block)**:
```
         è¾“å…¥ x
          â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”
      â”‚  æ’ç­‰  â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Conv-BN-ReLUâ”‚
    â”‚ Conv-BN     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
        x + F(x)  â† æ®‹å·®è¿æ¥
          â†“
        ReLU
```

**æ•°å­¦è¡¨è¾¾**:
```
y = F(x) + x
```
å…¶ä¸­ `F(x)` æ˜¯æ®‹å·®æ˜ å°„ï¼ˆ2-3å±‚å·ç§¯ï¼‰ã€‚

**ä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ**
- å¦‚æœæ’ç­‰æ˜ å°„æœ€ä¼˜ï¼Œç½‘ç»œåªéœ€å­¦ä¹  `F(x) = 0`
- æ¢¯åº¦å¯ä»¥ç›´æ¥é€šè¿‡å¿«æ·è¿æ¥ä¼ æ’­ï¼Œç¼“è§£æ¢¯åº¦æ¶ˆå¤±

**ResNetå®¶æ—**:
| æ¨¡å‹ | å±‚æ•° | å‚æ•°é‡ | ImageNet Top-5 é”™è¯¯ç‡ |
|------|------|--------|---------------------|
| ResNet-18 | 18 | 11.7M | ~10.8% |
| ResNet-34 | 34 | 21.8M | ~9.2% |
| ResNet-50 | 50 | 25.6M | ~7.1% |
| ResNet-101 | 101 | 44.5M | ~6.4% |
| ResNet-152 | 152 | 60.2M | ~5.7% |

**ä»£ç ç¤ºä¾‹**:
```python
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, padding=1)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)

        # å¿«æ·è¿æ¥ï¼ˆå¦‚æœç»´åº¦ä¸åŒ¹é…ï¼Œéœ€è¦1Ã—1å·ç§¯è°ƒæ•´ï¼‰
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 1, stride),
                nn.BatchNorm2d(out_channels)
            )
        else:
            self.shortcut = nn.Identity()

    def forward(self, x):
        residual = self.shortcut(x)
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += residual  # æ®‹å·®è¿æ¥
        return F.relu(out)
```

#### 2.5 EfficientNet (2019)

**æ ¸å¿ƒæ€æƒ³**: **å¤åˆç¼©æ”¾ (Compound Scaling)** - åŒæ—¶è°ƒæ•´æ·±åº¦ã€å®½åº¦ã€åˆ†è¾¨ç‡ã€‚

**ä¼ ç»Ÿæ–¹æ³• vs å¤åˆç¼©æ”¾**:
```
ä¼ ç»Ÿæ–¹æ³•ï¼š
- åŠ æ·±åº¦: ResNet-50 â†’ ResNet-101
- åŠ å®½åº¦: ResNet-50 (widthÃ—1.5)
- åŠ åˆ†è¾¨ç‡: 224Ã—224 â†’ 299Ã—299

å¤åˆç¼©æ”¾ï¼š
depth = Î±^Ï†, width = Î²^Ï†, resolution = Î³^Ï†
çº¦æŸ: Î± Â· Î²Â² Â· Î³Â² â‰ˆ 2
```

**EfficientNetå®¶æ—**:
| æ¨¡å‹ | å‚æ•°é‡ | ImageNet Top-1å‡†ç¡®ç‡ | æ¨ç†é€Ÿåº¦ |
|------|--------|---------------------|---------|
| EfficientNet-B0 | 5.3M | 77.1% | åŸºå‡† |
| EfficientNet-B1 | 7.8M | 79.1% | 1.2Ã— |
| EfficientNet-B3 | 12M | 81.6% | 1.8Ã— |
| EfficientNet-B7 | 66M | 84.3% | 6.1Ã— |

**ä¼˜åŠ¿**: åœ¨ç›¸åŒè®¡ç®—é‡ä¸‹å‡†ç¡®ç‡æ›´é«˜ï¼Œæˆ–åœ¨ç›¸åŒå‡†ç¡®ç‡ä¸‹é€Ÿåº¦æ›´å¿«ã€‚

---

### 3. ç›®æ ‡æ£€æµ‹ (Object Detection)

ç›®æ ‡æ£€æµ‹ = åˆ†ç±» + å®šä½

**è¾“å‡ºæ ¼å¼**:
```python
[
    {"class": "cat", "bbox": [x1, y1, x2, y2], "confidence": 0.95},
    {"class": "dog", "bbox": [x3, y3, x4, y4], "confidence": 0.88}
]
```

#### 3.1 ä¸¤é˜¶æ®µæ£€æµ‹å™¨: Faster R-CNN

**æµç¨‹**:
```
è¾“å…¥å›¾åƒ
  â†“
ç‰¹å¾æå–ç½‘ç»œ (Backbone: ResNet/VGG)
  â†“
RPN (åŒºåŸŸå»ºè®®ç½‘ç»œ) â†’ ç”Ÿæˆå€™é€‰æ¡†
  â†“
ROI Pooling â†’ å¯¹é½ç‰¹å¾
  â†“
åˆ†ç±» + è¾¹ç•Œæ¡†å›å½’
```

**ä¼˜ç‚¹**: å‡†ç¡®ç‡é«˜
**ç¼ºç‚¹**: é€Ÿåº¦æ…¢ï¼ˆ~5 FPSï¼‰

#### 3.2 å•é˜¶æ®µæ£€æµ‹å™¨: YOLO ç³»åˆ—

**æ ¸å¿ƒæ€æƒ³**: å°†æ£€æµ‹é—®é¢˜è½¬åŒ–ä¸ºå›å½’é—®é¢˜ï¼Œä¸€æ¬¡æ€§é¢„æµ‹æ‰€æœ‰è¾¹ç•Œæ¡†ã€‚

**YOLO v1-v11 æ¼”è¿›**:
| ç‰ˆæœ¬ | å‘å¸ƒå¹´ä»½ | å…³é”®åˆ›æ–° | mAP@0.5 | é€Ÿåº¦ |
|------|---------|---------|---------|------|
| YOLOv1 | 2016 | å•é˜¶æ®µæ£€æµ‹ | 63.4% | 45 FPS |
| YOLOv3 | 2018 | å¤šå°ºåº¦é¢„æµ‹ | 57.9% | 30 FPS |
| YOLOv5 | 2020 | å·¥ç¨‹ä¼˜åŒ– | 65.8% | 140 FPS |
| YOLOv8 | 2023 | Anchor-free | 53.9% | 80 FPS |
| YOLOv11 | 2024 | Transformerèåˆ | 54.7% | 90+ FPS |

**YOLOv11 æ¶æ„**:
```
è¾“å…¥(640Ã—640Ã—3)
  â†“
CSPDarknet53 Backbone
  â†“
PAN-FPN (ç‰¹å¾é‡‘å­—å¡”)
  â†“
Decoupled Head (è§£è€¦å¤´)
  â”œâ”€ åˆ†ç±»åˆ†æ”¯
  â””â”€ å›å½’åˆ†æ”¯
```

**åº”ç”¨åœºæ™¯**: å®æ—¶è§†é¢‘æ£€æµ‹ã€è‡ªåŠ¨é©¾é©¶ã€å·¥ä¸šè´¨æ£€

#### 3.3 åŸºäºTransformer: DETR

**æ ¸å¿ƒåˆ›æ–°**: å°†ç›®æ ‡æ£€æµ‹è§†ä¸º **é›†åˆé¢„æµ‹é—®é¢˜**ï¼Œæ— éœ€NMSåå¤„ç†ã€‚

**æ¶æ„**:
```
è¾“å…¥å›¾åƒ â†’ CNN Backbone â†’ Flatten
  â†“
Transformer Encoder
  â†“
Transformer Decoder (Nä¸ªæŸ¥è¯¢å‘é‡)
  â†“
å¹¶è¡Œé¢„æµ‹Nä¸ªå¯¹è±¡ï¼ˆclass + bboxï¼‰
```

**ä¼˜ç‚¹**: ç«¯åˆ°ç«¯è®­ç»ƒã€æ— éœ€æ‰‹å·¥è®¾è®¡anchor
**ç¼ºç‚¹**: è®­ç»ƒæ…¢ã€å°ç›®æ ‡æ£€æµ‹æ•ˆæœä¸€èˆ¬

---

### 4. å›¾åƒåˆ†å‰² (Image Segmentation)

#### 4.1 è¯­ä¹‰åˆ†å‰² (Semantic Segmentation)

**ç›®æ ‡**: ä¸ºæ¯ä¸ªåƒç´ åˆ†é…ç±»åˆ«æ ‡ç­¾ï¼ˆä¸åŒºåˆ†å®ä¾‹ï¼‰

**ç»å…¸æ¶æ„: U-Net**
```
ç¼–ç å™¨ï¼ˆä¸‹é‡‡æ ·ï¼‰          è§£ç å™¨ï¼ˆä¸Šé‡‡æ ·ï¼‰
     â†“                       â†‘
Conv-Pool â”€â”€â”€â”€â”€è·³è·ƒè¿æ¥â”€â”€â”€â†’ UpConv-Concat
     â†“                       â†‘
Conv-Pool â”€â”€â”€â”€â”€è·³è·ƒè¿æ¥â”€â”€â”€â†’ UpConv-Concat
     â†“                       â†‘
Conv-Pool                UpConv-Concat
```

**è·³è·ƒè¿æ¥ä½œç”¨**: èåˆé«˜åˆ†è¾¨ç‡æµ…å±‚ç‰¹å¾ä¸é«˜è¯­ä¹‰æ·±å±‚ç‰¹å¾ã€‚

**åº”ç”¨**: åŒ»å­¦å½±åƒåˆ†å‰²ã€è‡ªåŠ¨é©¾é©¶åœºæ™¯ç†è§£

#### 4.2 å®ä¾‹åˆ†å‰² (Instance Segmentation)

**ç›®æ ‡**: åŒºåˆ†åŒç±»åˆ«çš„ä¸åŒå®ä¾‹

**Mask R-CNN**:
```
Faster R-CNN
  â”œâ”€ åˆ†ç±»åˆ†æ”¯
  â”œâ”€ è¾¹ç•Œæ¡†å›å½’åˆ†æ”¯
  â””â”€ æ©ç åˆ†æ”¯ (FCN) â† æ–°å¢
```

**è¾“å‡º**: æ¯ä¸ªå®ä¾‹çš„ç±»åˆ« + è¾¹ç•Œæ¡† + åƒç´ çº§æ©ç 

#### 4.3 å…¨æ™¯åˆ†å‰² (Panoptic Segmentation)

**ç›®æ ‡**: è¯­ä¹‰åˆ†å‰² + å®ä¾‹åˆ†å‰²çš„ç»Ÿä¸€

**åº”ç”¨**: è‡ªåŠ¨é©¾é©¶ï¼ˆéœ€è¦è¯†åˆ«é“è·¯ã€è¡Œäººã€è½¦è¾†ç­‰ï¼‰

#### 4.4 æœ€æ–°è¿›å±•: Segment Anything (SAM)

**æ ¸å¿ƒæ€æƒ³**: é›¶æ ·æœ¬åˆ†å‰²ï¼Œè¾“å…¥æç¤ºï¼ˆç‚¹/æ¡†/æ–‡æœ¬ï¼‰å³å¯åˆ†å‰²ä»»æ„å¯¹è±¡ã€‚

**æ¶æ„**:
```
å›¾åƒç¼–ç å™¨ (ViT) + æç¤ºç¼–ç å™¨ + æ©ç è§£ç å™¨
```

**åº”ç”¨**: äº¤äº’å¼æ ‡æ³¨ã€è§†é¢‘å¯¹è±¡åˆ†å‰²

---

### 5. è¿ç§»å­¦ä¹  (Transfer Learning)

#### 5.1 ä¸ºä»€ä¹ˆéœ€è¦è¿ç§»å­¦ä¹ ï¼Ÿ

**æŒ‘æˆ˜**:
- ä»é›¶è®­ç»ƒå¤§å‹CNNéœ€è¦ç™¾ä¸‡çº§æ ‡æ³¨æ•°æ®
- è®­ç»ƒæ—¶é—´é•¿ï¼ˆå‡ å¤©åˆ°å‡ å‘¨ï¼‰
- è®¡ç®—èµ„æºæ˜‚è´µï¼ˆå¤šå¡GPUï¼‰

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨åœ¨ImageNetä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œè¿ç§»åˆ°ç›®æ ‡ä»»åŠ¡ã€‚

#### 5.2 è¿ç§»å­¦ä¹ ç­–ç•¥

**ç­–ç•¥1: å›ºå®šç‰¹å¾æå–å™¨**ï¼ˆæ•°æ®é‡<1000ï¼‰
```python
# åŠ è½½é¢„è®­ç»ƒResNet
model = torchvision.models.resnet50(pretrained=True)

# å†»ç»“æ‰€æœ‰å·ç§¯å±‚
for param in model.parameters():
    param.requires_grad = False

# åªè®­ç»ƒæœ€åçš„å…¨è¿æ¥å±‚
model.fc = nn.Linear(2048, num_classes)
```

**ç­–ç•¥2: å¾®è°ƒ (Fine-tuning)**ï¼ˆæ•°æ®é‡1000-10000ï¼‰
```python
model = torchvision.models.resnet50(pretrained=True)

# å†»ç»“å‰å‡ å±‚ï¼Œå¾®è°ƒåå‡ å±‚
for name, param in model.named_parameters():
    if "layer4" in name or "fc" in name:
        param.requires_grad = True
    else:
        param.requires_grad = False
```

**ç­–ç•¥3: å…¨ç½‘ç»œå¾®è°ƒ**ï¼ˆæ•°æ®é‡>10000ï¼‰
```python
model = torchvision.models.resnet50(pretrained=True)
model.fc = nn.Linear(2048, num_classes)

# ä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡
optimizer = torch.optim.Adam([
    {'params': model.fc.parameters(), 'lr': 1e-3},       # æ–°å±‚å¤§å­¦ä¹ ç‡
    {'params': model.layer4.parameters(), 'lr': 1e-4},   # åå±‚ä¸­å­¦ä¹ ç‡
    {'params': model.layer3.parameters(), 'lr': 1e-5}    # å‰å±‚å°å­¦ä¹ ç‡
])
```

#### 5.3 é¢„è®­ç»ƒæ¨¡å‹æ¥æº

**PyTorch Hub**:
```python
import torch
model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)
```

**Torchvision Models**:
```python
from torchvision import models
resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
efficientnet_b0 = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)
```

**Hugging Face Transformers** (Vision Transformer):
```python
from transformers import ViTModel
model = ViTModel.from_pretrained('google/vit-base-patch16-224')
```

---

## ğŸ› ï¸ å®è·µç¯èŠ‚

### ä»»åŠ¡1: æ‰‹å†™CNNå›¾åƒåˆ†ç±»å™¨

**ç›®æ ‡**: ä»é›¶å®ç°ä¸€ä¸ªCNNï¼Œåœ¨CIFAR-10ä¸Šè¾¾åˆ°70%+å‡†ç¡®ç‡

**å…³é”®ä»£ç ** (`notebooks/stage4/03-cnn-image-classification.ipynb` ç¬¬3èŠ‚):
```python
class SimpleCNN(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2)
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 4 * 4, 256),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x
```

### ä»»åŠ¡2: ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œè¿ç§»å­¦ä¹ 

**ç›®æ ‡**: åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šå¾®è°ƒResNet-50ï¼Œè¶…è¶Šä»é›¶è®­ç»ƒçš„æ¨¡å‹

**æ­¥éª¤**:
1. åŠ è½½é¢„è®­ç»ƒResNet-50
2. æ›¿æ¢æœ€åçš„å…¨è¿æ¥å±‚
3. å†»ç»“å‰80%çš„å±‚
4. ä½¿ç”¨å°å­¦ä¹ ç‡å¾®è°ƒ
5. å¯¹æ¯”ä»é›¶è®­ç»ƒ vs è¿ç§»å­¦ä¹ çš„æ”¶æ•›é€Ÿåº¦

**é¢„æœŸç»“æœ**:
- ä»é›¶è®­ç»ƒ: éœ€è¦50+ epochsè¾¾åˆ°60%å‡†ç¡®ç‡
- è¿ç§»å­¦ä¹ : 5 epochså³å¯è¾¾åˆ°80%å‡†ç¡®ç‡

### ä»»åŠ¡3: å¯è§†åŒ–CNNç‰¹å¾å›¾

**ç›®æ ‡**: ç†è§£CNNæ¯å±‚å­¦åˆ°çš„ç‰¹å¾

**å¯è§†åŒ–å†…å®¹**:
- ç¬¬1å±‚: è¾¹ç¼˜æ£€æµ‹å™¨ï¼ˆæ°´å¹³ã€å‚ç›´ã€å¯¹è§’çº¿ï¼‰
- ç¬¬3å±‚: çº¹ç†æ£€æµ‹å™¨
- ç¬¬5å±‚: å½¢çŠ¶æ£€æµ‹å™¨
- æœ€åä¸€å±‚: é«˜çº§è¯­ä¹‰ç‰¹å¾

**ä»£ç **:
```python
# æå–ä¸­é—´å±‚ç‰¹å¾
activations = {}
def get_activation(name):
    def hook(model, input, output):
        activations[name] = output.detach()
    return hook

model.layer1.register_forward_hook(get_activation('layer1'))
model.layer2.register_forward_hook(get_activation('layer2'))

# å‰å‘ä¼ æ’­
_ = model(image)

# å¯è§†åŒ–
plt.imshow(activations['layer1'][0, 0].cpu(), cmap='viridis')
```

---

## ğŸ“– æ‰©å±•é˜…è¯»

### ç»å…¸è®ºæ–‡

1. **ImageNet Classification with Deep CNNs** (AlexNet, 2012)
   - é“¾æ¥: [https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
   - é˜…è¯»æ—¶é—´: 1å°æ—¶

2. **Deep Residual Learning for Image Recognition** (ResNet, 2015)
   - é“¾æ¥: [https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)
   - é˜…è¯»æ—¶é—´: 1.5å°æ—¶

3. **You Only Look Once: Unified, Real-Time Object Detection** (YOLOv1, 2016)
   - é“¾æ¥: [https://arxiv.org/abs/1506.02640](https://arxiv.org/abs/1506.02640)
   - é˜…è¯»æ—¶é—´: 1å°æ—¶

4. **U-Net: Convolutional Networks for Biomedical Image Segmentation** (2015)
   - é“¾æ¥: [https://arxiv.org/abs/1505.04597](https://arxiv.org/abs/1505.04597)
   - é˜…è¯»æ—¶é—´: 45åˆ†é’Ÿ

### åœ¨çº¿èµ„æº

- **CS231n (Stanford)**: [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)
- **PyTorch Vision Tutorials**: [https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)
- **Papers with Code (CVæ’è¡Œæ¦œ)**: [https://paperswithcode.com/area/computer-vision](https://paperswithcode.com/area/computer-vision)

### å®æˆ˜é¡¹ç›®æ¨è

å®Œæˆæœ¬æ¨¡å—åï¼Œå»ºè®®å°è¯•ä»¥ä¸‹é¡¹ç›®ï¼š

- ğŸš€ **[P01: å·¥ä¸šè§†è§‰æ£€æµ‹](../projects/p01-industrial-vision/README.md)** - TensorFlowè¿ç§»å­¦ä¹ 
- ğŸš€ **[P02: YOLOv11å®æ—¶æ£€æµ‹](../projects/p02-yolov11-realtime/README.md)** - åŒæ¡†æ¶å®ç°ï¼ˆæ¨èï¼‰
- ğŸš€ **[P04: è‡ªåŠ¨é©¾é©¶å›¾åƒåˆ†å‰²](../projects/p04-image-segmentation/README.md)** - U-Net/DeepLabåŒæ¡†æ¶

---

## â“ å¸¸è§é—®é¢˜ (FAQ)

### Q1: CNN ä¸ºä»€ä¹ˆæ¯”å…¨è¿æ¥ç½‘ç»œæ›´é€‚åˆå¤„ç†å›¾åƒï¼Ÿ

**A**: ä¸‰ä¸ªæ ¸å¿ƒåŸå› ï¼š
1. **å‚æ•°å…±äº«**: åŒä¸€ä¸ªå·ç§¯æ ¸åœ¨æ•´ä¸ªå›¾åƒä¸Šå¤ç”¨ï¼Œå‡å°‘å‚æ•°é‡
2. **å±€éƒ¨è¿æ¥**: åˆ©ç”¨å›¾åƒçš„ç©ºé—´å±€éƒ¨æ€§ï¼Œæ¯ä¸ªç¥ç»å…ƒåªå…³æ³¨å±€éƒ¨åŒºåŸŸ
3. **å¹³ç§»ä¸å˜æ€§**: å¯¹ç‰©ä½“åœ¨å›¾åƒä¸­çš„ä½ç½®ä¸æ•æ„Ÿ

### Q2: å¦‚ä½•é€‰æ‹©åˆé€‚çš„CNNæ¶æ„ï¼Ÿ

**A**: æ ¹æ®åº”ç”¨åœºæ™¯é€‰æ‹©ï¼š
- **ç§»åŠ¨ç«¯/è¾¹ç¼˜è®¾å¤‡**: EfficientNet-B0, MobileNetV3 (å‚æ•°é‡<10M)
- **æœåŠ¡å™¨ç«¯é«˜ç²¾åº¦**: ResNet-101, EfficientNet-B7 (å‡†ç¡®ç‡ä¼˜å…ˆ)
- **å®æ—¶æ£€æµ‹**: YOLOv8, YOLOv11 (é€Ÿåº¦ä¼˜å…ˆ)
- **é€šç”¨åœºæ™¯**: ResNet-50 (æ€§èƒ½ä¸é€Ÿåº¦å¹³è¡¡)

### Q3: è¿ç§»å­¦ä¹ ä»€ä¹ˆæ—¶å€™æ•ˆæœå¥½ï¼Ÿ

**A**: æ»¡è¶³ä»¥ä¸‹æ¡ä»¶æ•ˆæœæœ€ä½³ï¼š
1. **æ•°æ®é‡å°**: <10,000å¼ å›¾åƒ
2. **ä»»åŠ¡ç›¸ä¼¼**: ç›®æ ‡ä»»åŠ¡ä¸ImageNetç±»ä¼¼ï¼ˆéƒ½æ˜¯è‡ªç„¶å›¾åƒï¼‰
3. **ç±»åˆ«ç›¸å…³**: å¦‚ImageNetåŒ…å«"ç‹—"ç±»åˆ«ï¼Œè¿ç§»åˆ°ç‹—ç§è¯†åˆ«æ•ˆæœå¥½

**ä¸é€‚ç”¨åœºæ™¯**:
- åŒ»å­¦å½±åƒï¼ˆXå…‰ã€CTï¼‰: ä¸è‡ªç„¶å›¾åƒå·®å¼‚å¤§
- å«æ˜Ÿé¥æ„Ÿå›¾åƒ: ä¸ImageNetå·®å¼‚å¤§
- å»ºè®®: å¯»æ‰¾é¢†åŸŸå†…çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚ChexNet foråŒ»ç–—ï¼‰

### Q4: å¦‚ä½•è°ƒè¯•CNNæ¨¡å‹ï¼Ÿ

**A**: 5æ­¥æ’æŸ¥æ³•ï¼š
1. **è¿‡æ‹Ÿåˆå•ä¸ªbatch**: ç¡®ä¿æ¨¡å‹æœ‰è¶³å¤Ÿå®¹é‡
2. **æ£€æŸ¥æ¢¯åº¦**: ä½¿ç”¨`torch.autograd.grad_check`
3. **å¯è§†åŒ–ç‰¹å¾å›¾**: æ£€æŸ¥æ˜¯å¦å­¦åˆ°æœ‰æ„ä¹‰çš„ç‰¹å¾
4. **å­¦ä¹ ç‡è°ƒä¼˜**: ä½¿ç”¨å­¦ä¹ ç‡æŸ¥æ‰¾å™¨ï¼ˆLR Finderï¼‰
5. **æ•°æ®å¢å¼º**: é˜²æ­¢è¿‡æ‹Ÿåˆ

### Q5: ä¸ºä»€ä¹ˆæ¨¡å‹åœ¨éªŒè¯é›†ä¸Šå‡†ç¡®ç‡å¾ˆä½ï¼Ÿ

**A**: å¯èƒ½åŸå› ï¼š
1. **è¿‡æ‹Ÿåˆ**: è®­ç»ƒé›†å‡†ç¡®ç‡é«˜ä½†éªŒè¯é›†ä½ â†’ å¢åŠ Dropout/æ­£åˆ™åŒ–
2. **æ¬ æ‹Ÿåˆ**: è®­ç»ƒé›†å‡†ç¡®ç‡ä¹Ÿä½ â†’ å¢åŠ æ¨¡å‹å®¹é‡/è®­ç»ƒæ›´ä¹…
3. **æ•°æ®æ³„éœ²**: éªŒè¯é›†åˆ†å¸ƒä¸è®­ç»ƒé›†ä¸åŒ â†’ æ£€æŸ¥æ•°æ®åˆ’åˆ†
4. **å­¦ä¹ ç‡å¤ªå¤§**: Losséœ‡è¡ä¸æ”¶æ•› â†’ é™ä½å­¦ä¹ ç‡

---

## âœ… å­¦ä¹ æ£€æŸ¥æ¸…å•

å®Œæˆæœ¬æ¨¡å—åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- [ ] è§£é‡Šå·ç§¯æ“ä½œçš„æ•°å­¦åŸç†å¹¶æ‰‹åŠ¨è®¡ç®—è¾“å‡ºå°ºå¯¸
- [ ] è¯´å‡ºè‡³å°‘3ä¸ªç»å…¸CNNæ¶æ„åŠå…¶å…³é”®åˆ›æ–°ç‚¹
- [ ] å®ç°ä¸€ä¸ªåŒ…å«å·ç§¯å±‚ã€æ± åŒ–å±‚ã€BNå±‚çš„ç®€å•CNN
- [ ] ä½¿ç”¨é¢„è®­ç»ƒResNet-50è¿›è¡Œè¿ç§»å­¦ä¹ 
- [ ] å¯è§†åŒ–CNNä¸åŒå±‚çš„ç‰¹å¾å›¾
- [ ] è§£é‡Šæ®‹å·®è¿æ¥ä¸ºä»€ä¹ˆèƒ½è§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
- [ ] åŒºåˆ†è¯­ä¹‰åˆ†å‰²ã€å®ä¾‹åˆ†å‰²ã€å…¨æ™¯åˆ†å‰²
- [ ] æ¯”è¾ƒYOLOä¸Faster R-CNNçš„ä¼˜ç¼ºç‚¹

---

## â­ï¸ ä¸‹ä¸€æ­¥

å®Œæˆæœ¬æ¨¡å—åï¼Œä½ å¯ä»¥ï¼š

1. **ç»§ç»­å­¦ä¹ **: [æ¨¡å—M03: è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€](../03-nlp-basics/README.md)
2. **å®æˆ˜é¡¹ç›®**: ä»[é¡¹ç›®åˆ—è¡¨](../projects/)ä¸­é€‰æ‹©æ„Ÿå…´è¶£çš„é¡¹ç›®å¼€å§‹å®è·µ
3. **æ·±å…¥ç ”ç©¶**: é˜…è¯»ç»å…¸è®ºæ–‡ï¼Œç†è§£æœ€æ–°æŠ€æœ¯è¿›å±•

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿæ‰“å¼€ [03-cnn-image-classification.ipynb](../../notebooks/stage4/03-cnn-image-classification.ipynb) å¼€å§‹åŠ¨æ‰‹å®è·µï¼** ğŸš€
